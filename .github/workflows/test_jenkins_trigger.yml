name: Test Jenkins Scoring Trigger

on:
  workflow_dispatch:
    inputs:
      plugin_dir:
        description: 'Plugin directory (e.g., brainscore_language/models/test_embedding_3)'
        required: true
        type: string
      plugin_type:
        description: 'Plugin type (models, benchmarks, data, metrics)'
        required: true
        type: choice
        options:
          - models
          - benchmarks
          - data
          - metrics
      test_email:
        description: 'Test email address'
        required: false
        type: string
        default: 'test@example.com'

jobs:
  test_jenkins_trigger:
    name: Test Jenkins Scoring Trigger
    runs-on: ubuntu-latest
    env:
      DOMAIN: language
      DOMAIN_ROOT: brainscore_language
      PYTHON_VERSION: 3.11
    
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install "." PyYAML

      - name: Mask sensitive inputs
        run: |
          # Mask email input to prevent it from appearing in logs
          echo "::add-mask::${{ inputs.test_email }}"

      - name: Read metadata file
        id: read_metadata
        run: |
          PLUGIN_DIR="${{ inputs.plugin_dir }}"
          
          # Write Python script to read metadata
          cat > /tmp/read_metadata.py << 'PYTHON_SCRIPT'
          import yaml
          import json
          import os
          import sys
          
          plugin_dir = os.environ.get('PLUGIN_DIR', '')
          metadata_dict = {}
          
          if plugin_dir:
              plugin_name = os.path.basename(plugin_dir.rstrip('/'))
              metadata_file = None
              
              # Check for metadata.yml or metadata.yaml
              if os.path.isfile(os.path.join(plugin_dir, 'metadata.yml')):
                  metadata_file = os.path.join(plugin_dir, 'metadata.yml')
              elif os.path.isfile(os.path.join(plugin_dir, 'metadata.yaml')):
                  metadata_file = os.path.join(plugin_dir, 'metadata.yaml')
              
              if metadata_file:
                  try:
                      with open(metadata_file, 'r') as f:
                          metadata_content = yaml.safe_load(f)
                          if metadata_content:
                              metadata_dict[plugin_name] = metadata_content
                  except Exception as e:
                      print(f'Error reading {metadata_file}: {e}', file=sys.stderr)
          
          # Build the final structure
          result = {
              'metadata': metadata_dict,
              'layer_mapping': None  # Language domain doesn't have layer mapping
          }
          
          print(json.dumps(result))
          PYTHON_SCRIPT
          
          export PLUGIN_DIR
          METADATA_AND_LAYER_MAP=$(python /tmp/read_metadata.py 2>/dev/null || echo '{"metadata": {}, "layer_mapping": null}')
          
          # Base64 encode for safe storage
          METADATA_AND_LAYER_MAP_B64=$(echo "$METADATA_AND_LAYER_MAP" | base64 | tr -d '\n')
          echo "metadata_and_layer_map_b64=${METADATA_AND_LAYER_MAP_B64}" >> $GITHUB_OUTPUT
          echo "Read metadata for plugin: $PLUGIN_DIR"
          echo "Metadata structure: $METADATA_AND_LAYER_MAP"

      - name: Build plugin info
        id: build_info
        run: |
          # Build minimal plugin_info JSON for testing
          METADATA_AND_LAYER_MAP_B64='${{ steps.read_metadata.outputs.metadata_and_layer_map_b64 }}'
          METADATA_AND_LAYER_MAP=$(echo "$METADATA_AND_LAYER_MAP_B64" | base64 -d)
          
          # Build compact JSON (no newlines) to avoid GITHUB_ENV/GITHUB_OUTPUT format issues
          PLUGIN_INFO=$(jq -c -n \
            --arg domain "language" \
            --arg email "${{ inputs.test_email }}" \
            --arg plugin_dirs "${{ inputs.plugin_dir }}" \
            --arg plugin_type "${{ inputs.plugin_type }}" \
            --argjson metadata_and_layer_map "$METADATA_AND_LAYER_MAP" \
            '{
              modifies_plugins: true,
              changed_plugins: {
                ($plugin_type): [$plugin_dirs | split("/") | last]
              },
              test_all_plugins: [],
              is_automergeable: true,
              run_score: "True",
              new_models: "",
              new_benchmarks: "",
              domain: $domain,
              email: $email,
              plugin_dirs: $plugin_dirs,
              plugin_type: $plugin_type,
              competition: "None",
              model_type: "artificialsubject",
              public: true,
              metadata_and_layer_map: $metadata_and_layer_map
            }')
          
          # Store PLUGIN_INFO in GITHUB_ENV for next step (contains email - GitHub Actions will mask it)
          echo "PLUGIN_INFO=${PLUGIN_INFO}" >> $GITHUB_ENV
          echo "plugin_info=${PLUGIN_INFO}" >> $GITHUB_OUTPUT
          
          # Mask email and other sensitive fields in log output
          PLUGIN_INFO_MASKED=$(echo "$PLUGIN_INFO" | jq -c 'if .email then .email = "***MASKED***" else . end | if .BSC_DATABASESECRET then .BSC_DATABASESECRET = "***MASKED***" else . end' 2>/dev/null || echo "{}")
          echo "Plugin info (sensitive data masked): ${PLUGIN_INFO_MASKED}"

      - name: Validate PLUGIN_INFO structure
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import json
          import sys
          
          plugin_info_str = os.environ.get('PLUGIN_INFO', '')
          if not plugin_info_str:
              print("Error: PLUGIN_INFO is empty", file=sys.stderr)
              sys.exit(1)
          
          # Check JSON size
          json_size = len(plugin_info_str)
          print(f"PLUGIN_INFO JSON size: {json_size} characters")
          
          # Check if JSON appears truncated (ends abruptly without closing braces)
          if not plugin_info_str.rstrip().endswith('}'):
              print("Warning: PLUGIN_INFO does not end with '}' - may be truncated", file=sys.stderr)
          
          try:
              plugin_info = json.loads(plugin_info_str)
              print("✓ PLUGIN_INFO is valid JSON")
              
              # Check required fields
              required_fields = ['domain', 'plugin_dirs', 'plugin_type', 'run_score']
              missing_fields = [f for f in required_fields if f not in plugin_info]
              if missing_fields:
                  print(f"Warning: Missing fields in PLUGIN_INFO: {missing_fields}", file=sys.stderr)
              else:
                  print("✓ All required fields present")
              
              # Show summary without sensitive data (truncate long values for display)
              safe_info = {}
              for k, v in plugin_info.items():
                  if k in ['email', 'BSC_DATABASESECRET']:
                      safe_info[k] = '***MASKED***'
                  elif k == 'metadata_and_layer_map' and isinstance(v, dict):
                      # Show structure but truncate long nested content
                      safe_info[k] = {
                          'metadata': f"<{len(v.get('metadata', {}))} plugin(s)>",
                          'layer_mapping': 'null' if v.get('layer_mapping') is None else f"<{len(v.get('layer_mapping', {}))} mapping(s)>"
                      }
                  elif isinstance(v, str) and len(v) > 100:
                      safe_info[k] = v[:100] + '...'
                  else:
                      safe_info[k] = v
              
              print(f"PLUGIN_INFO summary (sensitive/long data masked):")
              print(json.dumps(safe_info, indent=2))
              
              # Verify metadata_and_layer_map structure
              if 'metadata_and_layer_map' in plugin_info:
                  mam = plugin_info['metadata_and_layer_map']
                  if isinstance(mam, dict):
                      print(f"  - metadata_and_layer_map.metadata: {len(mam.get('metadata', {}))} plugin(s)")
                      print(f"  - metadata_and_layer_map.layer_mapping: {mam.get('layer_mapping')}")
                  else:
                      print(f"  - metadata_and_layer_map: {type(mam)} (expected dict)")
          except json.JSONDecodeError as e:
              print(f"Error: PLUGIN_INFO is not valid JSON: {e}", file=sys.stderr)
              print(f"JSON error at position {e.pos if hasattr(e, 'pos') else 'unknown'}", file=sys.stderr)
              # Show context around error
              if hasattr(e, 'pos') and e.pos < len(plugin_info_str):
                  start = max(0, e.pos - 50)
                  end = min(len(plugin_info_str), e.pos + 50)
                  print(f"Context around error: ...{plugin_info_str[start:end]}...", file=sys.stderr)
              sys.exit(1)
          PYTHON_SCRIPT

      - name: Trigger Jenkins scoring
        env:
          JENKINS_USER: ${{ secrets.JENKINS_USER }}
          JENKINS_TOKEN: ${{ secrets.JENKINS_TOKEN }}
          JENKINS_TRIGGER: ${{ secrets.JENKINS_TRIGGER }}
          PLUGIN_INFO: ${{ steps.build_info.outputs.plugin_info }}
        run: |
          # PLUGIN_INFO contains email - GitHub Actions automatically masks secrets in logs
          # Check that required secrets are set (without exposing values)
          if [ -z "$JENKINS_USER" ] || [ -z "$JENKINS_TOKEN" ] || [ -z "$JENKINS_TRIGGER" ]; then
            echo "Error: Missing required Jenkins secrets (JENKINS_USER, JENKINS_TOKEN, or JENKINS_TRIGGER)"
            exit 1
          fi
          echo "Jenkins secrets configured (values masked)"
          
          # Create a Python script to trigger Jenkins with debugging
          python3 << 'PYTHON_SCRIPT'
          import os
          import json
          import re
          import requests
          from requests.auth import HTTPBasicAuth
          
          jenkins_base = "http://www.brain-score-jenkins.com:8080"
          jenkins_user = os.environ['JENKINS_USER']
          jenkins_token = os.environ['JENKINS_TOKEN']
          jenkins_trigger = os.environ['JENKINS_TRIGGER']
          jenkins_job = "dev_score_plugins"
          plugin_info_str = os.environ['PLUGIN_INFO']
          
          # Parse plugin_info
          if isinstance(plugin_info_str, str):
              plugin_info = json.loads(plugin_info_str)
          else:
              plugin_info = plugin_info_str
          
          # Build URL (show without token for debugging)
          base_url = f'{jenkins_base}/job/{jenkins_job}/buildWithParameters'
          url_with_token = f'{base_url}?token={jenkins_trigger}'
          print(f"Jenkins URL (token masked): {base_url}?token=***MASKED***")
          
          # Build payload (filter out empty values)
          payload = {k: v for k, v in plugin_info.items() if plugin_info[k]}
          
          # Show payload structure (mask sensitive data)
          safe_payload = {}
          for k, v in payload.items():
              if k in ['email', 'BSC_DATABASESECRET']:
                  safe_payload[k] = '***MASKED***'
              elif isinstance(v, str) and len(v) > 200:
                  safe_payload[k] = v[:200] + '... (truncated)'
              else:
                  safe_payload[k] = v
          print(f"Payload keys: {list(payload.keys())}")
          print(f"Payload structure (sensitive data masked): {json.dumps(safe_payload, indent=2)}")
          
          # Make request
          try:
              auth_basic = HTTPBasicAuth(username=jenkins_user, password=jenkins_token)
              print(f"\nSending GET request to Jenkins...")
              response = requests.get(url_with_token, params=payload, auth=auth_basic, timeout=30)
              
              # Show response details
              print(f"Response status code: {response.status_code}")
              print(f"Response headers (filtered):")
              for key, value in response.headers.items():
                  if key.lower() not in ['set-cookie', 'authorization']:
                      print(f"  {key}: {value}")
              
              # Show response body (truncated, filtered for sensitive data)
              response_text = response.text[:1000] if response.text else "(empty)"
              
              # Mask potential sensitive patterns in response
              safe_response = response_text
              
              # Mask email addresses
              safe_response = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '***MASKED_EMAIL***', safe_response)
              
              # Mask tokens/API keys (long alphanumeric strings, typically 20+ chars)
              safe_response = re.sub(r'\b[A-Za-z0-9]{20,}\b', lambda m: '***MASKED_TOKEN***' if not m.group().startswith('http') else m.group(), safe_response)
              
              # Mask URLs with tokens/credentials
              safe_response = re.sub(r'https?://[^:]+:[^@\s]+@', 'https://***MASKED_CREDENTIALS***@', safe_response)
              safe_response = re.sub(r'[?&](token|key|secret|password|auth)=[^&\s"\']+', r'\1=***MASKED***', safe_response, flags=re.IGNORECASE)
              
              # Mask common secret patterns
              patterns_to_mask = [
                  (r'["\']?token["\']?\s*[:=]\s*["\']?[^"\'\s]+', 'token=***MASKED***'),
                  (r'["\']?api[_-]?key["\']?\s*[:=]\s*["\']?[^"\'\s]+', 'api_key=***MASKED***'),
                  (r'["\']?secret["\']?\s*[:=]\s*["\']?[^"\'\s]+', 'secret=***MASKED***'),
                  (r'["\']?password["\']?\s*[:=]\s*["\']?[^"\'\s]+', 'password=***MASKED***'),
              ]
              for pattern, replacement in patterns_to_mask:
                  safe_response = re.sub(pattern, replacement, safe_response, flags=re.IGNORECASE)
              
              print(f"Response body (first 1000 chars, sensitive data masked): {safe_response}")
              
              # Check if successful
              if response.status_code == 201:
                  print("✓ Jenkins job triggered successfully (HTTP 201 Created)")
                  # Try to extract queue URL if present
                  if 'Location' in response.headers:
                      print(f"Job location: {response.headers['Location']}")
              elif response.status_code == 200:
                  print("⚠ Jenkins returned HTTP 200 (may indicate job was queued or already exists)")
              else:
                  print(f"✗ Jenkins returned HTTP {response.status_code} (unexpected status)")
                  response.raise_for_status()
                  
          except requests.exceptions.HTTPError as e:
              print(f"✗ HTTP Error: {e}")
              if hasattr(e, 'response') and e.response is not None:
                  print(f"  Response status: {e.response.status_code}")
                  # Apply same filtering to error response
                  error_text = e.response.text[:1000] if e.response.text else "(empty)"
                  safe_error = error_text
                  safe_error = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '***MASKED_EMAIL***', safe_error)
                  safe_error = re.sub(r'\b[A-Za-z0-9]{20,}\b', lambda m: '***MASKED_TOKEN***' if not m.group().startswith('http') else m.group(), safe_error)
                  safe_error = re.sub(r'https?://[^:]+:[^@\s]+@', 'https://***MASKED_CREDENTIALS***@', safe_error)
                  safe_error = re.sub(r'[?&](token|key|secret|password|auth)=[^&\s"\']+', r'\1=***MASKED***', safe_error, flags=re.IGNORECASE)
                  print(f"  Response body (first 1000 chars, sensitive data masked): {safe_error}")
              raise
          except requests.exceptions.RequestException as e:
              print(f"✗ Request Error: {e}")
              raise
          except Exception as e:
              print(f"✗ Unexpected Error: {e}")
              raise
          PYTHON_SCRIPT
