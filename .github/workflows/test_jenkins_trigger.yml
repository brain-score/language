name: Test Jenkins Scoring Trigger

on:
  workflow_dispatch:
    inputs:
      plugin_dir:
        description: 'Plugin directory (e.g., brainscore_language/models/test_embedding_3)'
        required: true
        type: string
      plugin_type:
        description: 'Plugin type (models, benchmarks, data, metrics)'
        required: true
        type: choice
        options:
          - models
          - benchmarks
          - data
          - metrics
      test_email:
        description: 'Test email address'
        required: false
        type: string
        default: 'test@example.com'

jobs:
  test_jenkins_trigger:
    name: Test Jenkins Scoring Trigger
    runs-on: ubuntu-latest
    env:
      DOMAIN: language
      DOMAIN_ROOT: brainscore_language
      PYTHON_VERSION: 3.11
    
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install "." PyYAML

      - name: Mask sensitive inputs
        run: |
          # Mask email input to prevent it from appearing in logs
          echo "::add-mask::${{ inputs.test_email }}"

      - name: Read metadata file
        id: read_metadata
        run: |
          PLUGIN_DIR="${{ inputs.plugin_dir }}"
          
          # Write Python script to read metadata
          cat > /tmp/read_metadata.py << 'PYTHON_SCRIPT'
          import yaml
          import json
          import os
          import sys
          
          plugin_dir = os.environ.get('PLUGIN_DIR', '')
          metadata_dict = {}
          
          if plugin_dir:
              plugin_name = os.path.basename(plugin_dir.rstrip('/'))
              metadata_file = None
              
              # Check for metadata.yml or metadata.yaml
              if os.path.isfile(os.path.join(plugin_dir, 'metadata.yml')):
                  metadata_file = os.path.join(plugin_dir, 'metadata.yml')
              elif os.path.isfile(os.path.join(plugin_dir, 'metadata.yaml')):
                  metadata_file = os.path.join(plugin_dir, 'metadata.yaml')
              
              if metadata_file:
                  try:
                      with open(metadata_file, 'r') as f:
                          metadata_content = yaml.safe_load(f)
                          if metadata_content:
                              metadata_dict[plugin_name] = metadata_content
                  except Exception as e:
                      print(f'Error reading {metadata_file}: {e}', file=sys.stderr)
          
          # Build the final structure
          result = {
              'metadata': metadata_dict,
              'layer_mapping': None  # Language domain doesn't have layer mapping
          }
          
          print(json.dumps(result))
          PYTHON_SCRIPT
          
          export PLUGIN_DIR
          METADATA_AND_LAYER_MAP=$(python /tmp/read_metadata.py 2>/dev/null || echo '{"metadata": {}, "layer_mapping": null}')
          
          # Base64 encode for safe storage
          METADATA_AND_LAYER_MAP_B64=$(echo "$METADATA_AND_LAYER_MAP" | base64 | tr -d '\n')
          echo "metadata_and_layer_map_b64=${METADATA_AND_LAYER_MAP_B64}" >> $GITHUB_OUTPUT
          echo "Read metadata for plugin: $PLUGIN_DIR"
          echo "Metadata structure: $METADATA_AND_LAYER_MAP"

      - name: Build plugin info
        id: build_info
        run: |
          # Build minimal plugin_info JSON for testing
          METADATA_AND_LAYER_MAP_B64='${{ steps.read_metadata.outputs.metadata_and_layer_map_b64 }}'
          METADATA_AND_LAYER_MAP=$(echo "$METADATA_AND_LAYER_MAP_B64" | base64 -d)
          
          PLUGIN_INFO=$(jq -n \
            --arg domain "language" \
            --arg email "${{ inputs.test_email }}" \
            --arg plugin_dirs "${{ inputs.plugin_dir }}" \
            --arg plugin_type "${{ inputs.plugin_type }}" \
            --argjson metadata_and_layer_map "$METADATA_AND_LAYER_MAP" \
            '{
              modifies_plugins: true,
              changed_plugins: {
                ($plugin_type): [$plugin_dirs | split("/") | last]
              },
              test_all_plugins: [],
              is_automergeable: true,
              run_score: "True",
              new_models: "",
              new_benchmarks: "",
              domain: $domain,
              email: $email,
              plugin_dirs: $plugin_dirs,
              plugin_type: $plugin_type,
              competition: "None",
              model_type: "artificialsubject",
              public: true,
              metadata_and_layer_map: $metadata_and_layer_map
            }')
          
          # Mask email before storing in outputs (GitHub Actions will also mask secrets)
          PLUGIN_INFO_MASKED=$(echo "$PLUGIN_INFO" | jq -c 'if .email then .email = "***MASKED***" else . end | if .BSC_DATABASESECRET then .BSC_DATABASESECRET = "***MASKED***" else . end' 2>/dev/null || echo "{}")
          echo "Plugin info (sensitive data masked): ${PLUGIN_INFO_MASKED}"
          
          # Store PLUGIN_INFO in GITHUB_ENV for next step (contains email - already masked above)
          echo "PLUGIN_INFO=${PLUGIN_INFO}" >> $GITHUB_ENV
          echo "plugin_info=${PLUGIN_INFO}" >> $GITHUB_OUTPUT

      - name: Validate PLUGIN_INFO structure
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import json
          import sys
          
          plugin_info_str = os.environ.get('PLUGIN_INFO', '')
          if not plugin_info_str:
              print("Error: PLUGIN_INFO is empty", file=sys.stderr)
              sys.exit(1)
          
          # Check JSON size
          json_size = len(plugin_info_str)
          print(f"PLUGIN_INFO JSON size: {json_size} characters")
          
          # Check if JSON appears truncated (ends abruptly without closing braces)
          if not plugin_info_str.rstrip().endswith('}'):
              print("Warning: PLUGIN_INFO does not end with '}' - may be truncated", file=sys.stderr)
          
          try:
              plugin_info = json.loads(plugin_info_str)
              print("✓ PLUGIN_INFO is valid JSON")
              
              # Check required fields
              required_fields = ['domain', 'plugin_dirs', 'plugin_type', 'run_score']
              missing_fields = [f for f in required_fields if f not in plugin_info]
              if missing_fields:
                  print(f"Warning: Missing fields in PLUGIN_INFO: {missing_fields}", file=sys.stderr)
              else:
                  print("✓ All required fields present")
              
              # Show summary without sensitive data (truncate long values for display)
              safe_info = {}
              for k, v in plugin_info.items():
                  if k in ['email', 'BSC_DATABASESECRET']:
                      safe_info[k] = '***MASKED***'
                  elif k == 'metadata_and_layer_map' and isinstance(v, dict):
                      # Show structure but truncate long nested content
                      safe_info[k] = {
                          'metadata': f"<{len(v.get('metadata', {}))} plugin(s)>",
                          'layer_mapping': 'null' if v.get('layer_mapping') is None else f"<{len(v.get('layer_mapping', {}))} mapping(s)>"
                      }
                  elif isinstance(v, str) and len(v) > 100:
                      safe_info[k] = v[:100] + '...'
                  else:
                      safe_info[k] = v
              
              print(f"PLUGIN_INFO summary (sensitive/long data masked):")
              print(json.dumps(safe_info, indent=2))
              
              # Verify metadata_and_layer_map structure
              if 'metadata_and_layer_map' in plugin_info:
                  mam = plugin_info['metadata_and_layer_map']
                  if isinstance(mam, dict):
                      print(f"  - metadata_and_layer_map.metadata: {len(mam.get('metadata', {}))} plugin(s)")
                      print(f"  - metadata_and_layer_map.layer_mapping: {mam.get('layer_mapping')}")
                  else:
                      print(f"  - metadata_and_layer_map: {type(mam)} (expected dict)")
          except json.JSONDecodeError as e:
              print(f"Error: PLUGIN_INFO is not valid JSON: {e}", file=sys.stderr)
              print(f"JSON error at position {e.pos if hasattr(e, 'pos') else 'unknown'}", file=sys.stderr)
              # Show context around error
              if hasattr(e, 'pos') and e.pos < len(plugin_info_str):
                  start = max(0, e.pos - 50)
                  end = min(len(plugin_info_str), e.pos + 50)
                  print(f"Context around error: ...{plugin_info_str[start:end]}...", file=sys.stderr)
              sys.exit(1)
          PYTHON_SCRIPT

      - name: Trigger Jenkins scoring
        env:
          JENKINS_USER: ${{ secrets.JENKINS_USER }}
          JENKINS_TOKEN: ${{ secrets.JENKINS_TOKEN }}
          JENKINS_TRIGGER: ${{ secrets.JENKINS_TRIGGER }}
          PLUGIN_INFO: ${{ steps.build_info.outputs.plugin_info }}
        run: |
          # PLUGIN_INFO contains email - GitHub Actions automatically masks secrets in logs
          # Check that required secrets are set (without exposing values)
          if [ -z "$JENKINS_USER" ] || [ -z "$JENKINS_TOKEN" ] || [ -z "$JENKINS_TRIGGER" ]; then
            echo "Error: Missing required Jenkins secrets (JENKINS_USER, JENKINS_TOKEN, or JENKINS_TRIGGER)"
            exit 1
          fi
          echo "Jenkins secrets configured (values masked)"
          
          # Trigger Jenkins (suppress output to prevent exposure of sensitive data)
          # Capture exit code separately
          set +e
          python3 -c 'from brainscore_core.submission.endpoints import call_jenkins; import os; call_jenkins(os.environ["PLUGIN_INFO"])' >/tmp/jenkins_output.log 2>&1
          JENKINS_EXIT_CODE=$?
          set -e
          
          if [ $JENKINS_EXIT_CODE -ne 0 ]; then
            echo "Jenkins scoring trigger failed (exit code: $JENKINS_EXIT_CODE)"
            echo "Checking for error messages (sensitive data will be masked by GitHub Actions):"
            # Show error output (GitHub Actions will mask secrets automatically)
            # Filter out email patterns and token patterns, but keep PLUGIN_INFO for debugging
            cat /tmp/jenkins_output.log | \
              grep -v -E "@.*\.(com|org|edu|net)" | \
              grep -v -i "token" | \
              grep -v -i "secret" || \
              cat /tmp/jenkins_output.log
            exit 1
          fi
          echo "Jenkins scoring job triggered successfully"
