name: Plugin Submission Orchestrator

# Orchestration workflow for LLM evaluations
# Single entry point for all plugin submissions (models, benchmarks, metrics, data)
# Consolidates all submission logic into one clear, sequential flow

on:
  pull_request:
    types: [opened, synchronize, labeled]
  pull_request_target:
    types: [closed]
    branches: [main]

permissions:
  contents: write
  pull-requests: write
  issues: write
  checks: read
  statuses: read

env:
  DOMAIN: language
  DOMAIN_ROOT: brainscore_language
  PYTHON_VERSION: '3.11'

jobs:
  # ============================================================================
  # JOB 1: Detect and Classify Changes
  # ============================================================================
  detect_changes:
    name: "1. Detect Changes"
    runs-on: ubuntu-latest
    outputs:
      has_plugins: ${{ steps.detect.outputs.has_plugins }}
      plugin_type: ${{ steps.detect.outputs.plugin_type }}
      plugin_dirs: ${{ steps.detect.outputs.plugin_dirs }}
      has_new_models: ${{ steps.detect.outputs.has_new_models }}
      metadata_only: ${{ steps.detect.outputs.metadata_only }}
      needs_scoring: ${{ steps.detect.outputs.needs_scoring }}
      needs_mapping: ${{ steps.detect.outputs.needs_mapping }}
      needs_metadata_generation: ${{ steps.detect.outputs.needs_metadata_generation }}
      is_automergeable: ${{ steps.detect.outputs.is_automergeable }}
      plugin_info_json: ${{ steps.detect.outputs.plugin_info_json }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Get changed files
        id: changed_files
        run: |
          if [ "${{ github.event_name }}" == "pull_request_target" ] && [ "${{ github.event.pull_request.merged }}" == "true" ]; then
            # Post-merge: compare merge commit to previous
            git fetch origin refs/pull/${{ github.event.number }}/head
            MERGE_COMMIT=$(git log --format='%H %P' --all | grep "$(git rev-parse FETCH_HEAD)$" | cut -f1 -d' ')
            CHANGED_FILES=$(git diff --name-only origin/main~1 $MERGE_COMMIT | tr '\n' ' ' || echo "")
          else
            # Pre-merge: use GitHub API to get changed files (more reliable than git diff)
            # This works even when PR is reopened or refs are not set up correctly
            CHANGED_FILES=$(gh pr view ${{ github.event.pull_request.number }} --json files --jq '.files[].path' | tr '\n' ' ' || echo "")
            
            # Fallback to git diff if API fails or returns empty
            if [ -z "$CHANGED_FILES" ] || [ "$CHANGED_FILES" = " " ]; then
              echo "GitHub API returned no files, trying git diff fallback..."
              # Ensure base ref is fetched
              BASE_REF="${{ github.event.pull_request.base.ref }}"
              BASE_SHA="${{ github.event.pull_request.base.sha }}"
              HEAD_SHA="${{ github.event.pull_request.head.sha }}"
              
              # Fetch base branch and PR head
              git fetch origin ${BASE_REF} || true
              git fetch origin ${HEAD_SHA} || true
              
              # Try multiple methods to get changed files
              if [ -n "$BASE_SHA" ] && [ -n "$HEAD_SHA" ]; then
                CHANGED_FILES=$(git diff --name-only ${BASE_SHA}...${HEAD_SHA} | tr '\n' ' ' || echo "")
              fi
              
              if [ -z "$CHANGED_FILES" ] || [ "$CHANGED_FILES" = " " ]; then
                CHANGED_FILES=$(git diff --name-only origin/${BASE_REF}...HEAD | tr '\n' ' ' || echo "")
              fi
            fi
          fi
          echo "CHANGED_FILES=${CHANGED_FILES}" >> $GITHUB_ENV
          echo "Changed files: ${CHANGED_FILES}"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Detect plugin changes
        id: detect
        run: |
          # Handle empty CHANGED_FILES gracefully
          CHANGED_FILES="${{ env.CHANGED_FILES }}"
          if [ -z "$CHANGED_FILES" ]; then
            echo "No changed files detected, using empty string"
            CHANGED_FILES=""
          fi
          
          # Get plugin info - handle errors gracefully
          PLUGIN_INFO=$(python -W ignore -c "
          from brainscore_core.plugin_management.parse_plugin_changes import get_scoring_info
          import json
          try:
              result = get_scoring_info('${CHANGED_FILES}', '${{ env.DOMAIN_ROOT }}')
              print(json.dumps(result) if result else '{}')
          except Exception as e:
              print(json.dumps({'error': str(e)}))
          " 2>/dev/null || echo '{}')
          
          # Validate JSON output
          if ! echo "$PLUGIN_INFO" | jq empty 2>/dev/null; then
            echo "Warning: Invalid JSON from get_scoring_info, using empty object"
            PLUGIN_INFO='{}'
          fi
          
          echo "PLUGIN_INFO=${PLUGIN_INFO}" >> $GITHUB_ENV
          
          # Extract outputs and normalize to lowercase strings
          # Force single scalar values to prevent multiline output from jq
          HAS_PLUGINS_RAW=$(echo "$PLUGIN_INFO" | jq -r 'if .modifies_plugins == true then "true" else "false" end' | head -n 1)
          HAS_PLUGINS=$(echo "$HAS_PLUGINS_RAW" | tr '[:upper:]' '[:lower:]')
          PLUGIN_TYPE=$(echo "$PLUGIN_INFO" | jq -r '.plugin_type // ""' | head -n 1)
          # run_score is returned as string "True" or "False" (capitalized) from get_scoring_info
          # run_score is returned as string "True" or "False" (capitalized) from get_scoring_info
          # Extract the value and normalize to lowercase
          NEEDS_SCORING_RAW=$(echo "$PLUGIN_INFO" | jq -r '.run_score // "False"' | head -n 1)
          NEEDS_SCORING=$(echo "$NEEDS_SCORING_RAW" | tr '[:upper:]' '[:lower:]')
          IS_AUTOMERGEABLE_RAW=$(echo "$PLUGIN_INFO" | jq -r 'if .is_automergeable == true then "true" else "false" end' | head -n 1)
          IS_AUTOMERGEABLE=$(echo "$IS_AUTOMERGEABLE_RAW" | tr '[:upper:]' '[:lower:]')
          
          # Check for new models
          NEW_MODELS=$(echo "$PLUGIN_INFO" | jq -r '.new_models // []' | head -n 1)
          HAS_NEW_MODELS=$(if [ "$NEW_MODELS" != "[]" ] && [ "$NEW_MODELS" != "null" ] && [ -n "$NEW_MODELS" ]; then echo "true"; else echo "false"; fi)
          
          # Extract plugin directories (construct full paths from model/benchmark names)
          # get_scoring_info returns just the plugin names, so we need to construct full paths
          MODELS=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.models[]? // empty' | head -n 1)
          BENCHMARKS=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.benchmarks[]? // empty' | head -n 1)
          PLUGIN_DIRS=""
          if [ -n "$MODELS" ]; then
            # Construct full path: DOMAIN_ROOT/models/PLUGIN_NAME
            for model in $(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.models[]? // empty'); do
              if [ -n "$model" ]; then
                if [ -z "$PLUGIN_DIRS" ]; then
                  PLUGIN_DIRS="${DOMAIN_ROOT}/models/${model}"
                else
                  PLUGIN_DIRS="${PLUGIN_DIRS},${DOMAIN_ROOT}/models/${model}"
                fi
              fi
            done
          fi
          if [ -n "$BENCHMARKS" ]; then
            for benchmark in $(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.benchmarks[]? // empty'); do
              if [ -n "$benchmark" ]; then
                if [ -z "$PLUGIN_DIRS" ]; then
                  PLUGIN_DIRS="${DOMAIN_ROOT}/benchmarks/${benchmark}"
                else
                  PLUGIN_DIRS="${PLUGIN_DIRS},${DOMAIN_ROOT}/benchmarks/${benchmark}"
                fi
              fi
            done
          fi
          
          # Check if metadata only
          NON_METADATA=$(echo "$CHANGED_FILES" | tr ' ' '\n' | grep -Ev "metadata\.ya?ml" || true)
          METADATA_ONLY="false"
          if [ -z "$NON_METADATA" ] && [ "$HAS_PLUGINS" = "true" ]; then
            METADATA_ONLY="true"
          fi
          
          # Determine if mapping needed (for new models)
          # Layer mapping is only needed for vision domain, not language
          NEEDS_MAPPING="false"
          if [ "$DOMAIN" != "language" ] && [ "$HAS_NEW_MODELS" = "true" ] && [ "$NEEDS_SCORING" = "true" ]; then
            NEEDS_MAPPING="true"
          fi
          
          # Check if new plugins need metadata generation (missing metadata.yml)
          NEEDS_METADATA_GENERATION="false"
          if [ "$HAS_PLUGINS" = "true" ] && [ "$METADATA_ONLY" = "false" ]; then
            # Check if any plugin directories are missing metadata.yml
            IFS=',' read -ra DIRS <<< "$PLUGIN_DIRS"
            for dir in "${DIRS[@]}"; do
              if [ -n "$dir" ]; then
                # Check if metadata.yml or metadata.yaml exists
                if [ ! -f "${dir}/metadata.yml" ] && [ ! -f "${dir}/metadata.yaml" ]; then
                  NEEDS_METADATA_GENERATION="true"
                  echo "Plugin directory missing metadata: ${dir}"
                  break
                fi
              fi
            done
          fi
          
          # Set outputs - use simple echo format (GitHub Actions expects key=value format)
          echo "has_plugins=${HAS_PLUGINS:-false}" >> $GITHUB_OUTPUT
          echo "plugin_type=${PLUGIN_TYPE:-}" >> $GITHUB_OUTPUT
          echo "plugin_dirs=${PLUGIN_DIRS:-}" >> $GITHUB_OUTPUT
          echo "has_new_models=${HAS_NEW_MODELS:-false}" >> $GITHUB_OUTPUT
          echo "metadata_only=${METADATA_ONLY:-false}" >> $GITHUB_OUTPUT
          echo "needs_scoring=${NEEDS_SCORING:-false}" >> $GITHUB_OUTPUT
          echo "needs_mapping=${NEEDS_MAPPING:-false}" >> $GITHUB_OUTPUT
          echo "needs_metadata_generation=${NEEDS_METADATA_GENERATION:-false}" >> $GITHUB_OUTPUT
          echo "is_automergeable=${IS_AUTOMERGEABLE:-false}" >> $GITHUB_OUTPUT
          # Store plugin_info_json as base64-encoded string to avoid special character issues
          if [ -n "$PLUGIN_INFO" ]; then
            PLUGIN_INFO_B64=$(echo "$PLUGIN_INFO" | base64 | tr -d '\n')
            echo "plugin_info_json=${PLUGIN_INFO_B64}" >> $GITHUB_OUTPUT
          else
            echo "plugin_info_json=" >> $GITHUB_OUTPUT
          fi
          
          echo "Detection results:"
          echo "  Has plugins: ${HAS_PLUGINS}"
          echo "  Needs scoring: ${NEEDS_SCORING}"
          echo "  Needs mapping: ${NEEDS_MAPPING}"
          echo "  Metadata only: ${METADATA_ONLY}"
          echo "  Needs metadata generation: ${NEEDS_METADATA_GENERATION}"
          echo "  Changed files: ${CHANGED_FILES}"
          echo "  Plugin info JSON: ${PLUGIN_INFO}"

  # ============================================================================
  # JOB 2: Validate PR (Pre-merge only)
  # ============================================================================
  validate_pr:
    name: "2. Validate PR"
    needs: detect_changes
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.has_plugins == 'true'
    runs-on: ubuntu-latest
    outputs:
      is_automergeable: ${{ steps.validate.outputs.is_automergeable }}
      all_tests_pass: ${{ steps.validate.outputs.all_tests_pass }}
      pr_number: ${{ steps.get_pr_number.outputs.pr_number }}
      is_automerge_web: ${{ steps.check_label.outputs.is_automerge_web }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Get PR number
        id: get_pr_number
        run: |
          echo "pr_number=${{ github.event.pull_request.number }}" >> $GITHUB_OUTPUT

      - name: Check for automerge labels
        id: check_label
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          LABELS_JSON=$(gh pr view ${{ github.event.pull_request.number }} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "is_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "is_automerge_web=false" >> $GITHUB_OUTPUT
          fi
          
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge" or .name == "automerge-web")' >/dev/null; then
            echo "has_automerge_label=true" >> $GITHUB_OUTPUT
          else
            echo "has_automerge_label=false" >> $GITHUB_OUTPUT
          fi

      - name: Validate PR
        id: validate
        run: |
          RESULT=$(python brainscore_language/submission/actions_helpers.py validate_pr \
            --pr-number ${{ github.event.pull_request.number }} \
            --pr-head ${{ github.event.pull_request.head.sha }} \
            --is-automerge-web ${{ steps.check_label.outputs.is_automerge_web }})
          
          # Parse JSON output and set step outputs
          IS_AUTOMERGEABLE=$(echo "$RESULT" | jq -r '.is_automergeable // false' | head -n 1)
          ALL_TESTS_PASS=$(echo "$RESULT" | jq -r '.all_tests_pass // false' | head -n 1)
          
          echo "is_automergeable=${IS_AUTOMERGEABLE}" >> $GITHUB_OUTPUT
          echo "all_tests_pass=${ALL_TESTS_PASS}" >> $GITHUB_OUTPUT
          
          echo "Validation results:"
          echo "$RESULT" | jq '.'

  # ============================================================================
  # JOB 3: Update Existing Metadata (Conditional - only if metadata-only changes)
  # ============================================================================
  process_metadata:
    name: "3. Update Existing Metadata"
    needs: [detect_changes, validate_pr]
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.metadata_only == 'true'
    uses: ./.github/workflows/metadata_handler.yml
    with:
      plugin-dir: ${{ needs.detect_changes.outputs.plugin_dirs }}
      plugin-type: ${{ needs.detect_changes.outputs.plugin_type }}
      domain: language
      db-connection: true
    secrets:
      BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      APPROVAL_TOKEN: ${{ secrets.APPROVAL_TOKEN }}

  # ============================================================================
  # JOB 4: Generate Metadata (Conditional - for new plugins without metadata.yml)
  # ============================================================================
  generate_metadata:
    name: "4. Generate Metadata"
    needs: [detect_changes, validate_pr]
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.needs_metadata_generation == 'true' &&
      needs.validate_pr.outputs.all_tests_pass == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: "us-east-1"

      - name: Configure Git
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      - name: Generate metadata for plugins
        env:
          BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # TEMPORARY: Using hardcoded metadata until language metadata generation is fixed
          # TODO: Replace with actual metadata generation once language metadata is working
          
          # Split comma-separated plugin directories
          IFS=',' read -ra PLUGIN_DIRS <<< "${{ needs.detect_changes.outputs.plugin_dirs }}"
          
          # Track generated plugins by type for commit message
          GENERATED_MODELS=()
          GENERATED_BENCHMARKS=()
          
          for dir in "${PLUGIN_DIRS[@]}"; do
            if [ -n "$dir" ]; then
              # Determine plugin type from directory path
              if [[ "$dir" == *"/models/"* ]]; then
                PLUGIN_TYPE="models"
              elif [[ "$dir" == *"/benchmarks/"* ]]; then
                PLUGIN_TYPE="benchmarks"
              else
                echo "Could not determine plugin type for ${dir}, skipping"
                continue
              fi
              
              # Extract plugin name from directory path
              PLUGIN_NAME=$(basename "$dir")
              
              # Check if metadata.yml exists
              if [ ! -f "${dir}/metadata.yml" ] && [ ! -f "${dir}/metadata.yaml" ]; then
                echo "Generating metadata for: ${dir} (type: ${PLUGIN_TYPE})"
                
                # TEMPORARY: Using hardcoded metadata until language metadata generation is fixed
                # TODO: Replace hardcoded_metadata with actual metadata generation once language metadata is working
                # To switch to real metadata generation, change the import below to:
                # from brainscore_core.plugin_management.handle_metadata import generate_metadata
                # and replace the function call accordingly
                if python brainscore_language/submission/hardcoded_metadata.py "${dir}" "${PLUGIN_TYPE}"; then
                  # Add the generated metadata file to git immediately
                  if [ -f "${dir}/metadata.yml" ]; then
                    git add "${dir}/metadata.yml"
                    echo "Added ${dir}/metadata.yml to git"
                  elif [ -f "${dir}/metadata.yaml" ]; then
                    git add "${dir}/metadata.yaml"
                    echo "Added ${dir}/metadata.yaml to git"
                  fi
                  # Track this plugin by type for commit message
                  if [ "$PLUGIN_TYPE" == "models" ]; then
                    GENERATED_MODELS+=("${PLUGIN_NAME}")
                  else
                    GENERATED_BENCHMARKS+=("${PLUGIN_NAME}")
                  fi
                else
                  echo "Metadata generation failed for ${dir}, continuing..."
                fi
                
                # ACTUAL METADATA GENERATION (COMMENTED OUT - uncomment when ready):
                # python -c "
                # from brainscore_core.plugin_management.handle_metadata import generate_metadata
                # metadata_path = generate_metadata('$dir', '$PLUGIN_TYPE', domain='language')
                # if metadata_path:
                #     print(f'Generated metadata at: {metadata_path}')
                # else:
                #     print(f'Failed to generate metadata for {dir}')
                #     exit(1)
                # " || echo "Metadata generation failed for ${dir}, continuing..."
              else
                echo "Metadata already exists for: ${dir}, skipping generation"
              fi
            fi
          done
          
          # Store generated plugins lists for commit message
          if [ ${#GENERATED_MODELS[@]} -gt 0 ]; then
            echo "GENERATED_MODELS=$(IFS=','; echo "${GENERATED_MODELS[*]}")" >> $GITHUB_ENV
          fi
          if [ ${#GENERATED_BENCHMARKS[@]} -gt 0 ]; then
            echo "GENERATED_BENCHMARKS=$(IFS=','; echo "${GENERATED_BENCHMARKS[*]}")" >> $GITHUB_ENV
          fi

      - name: Commit generated metadata files
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Check if there are any staged changes (metadata files were added during generation)
          if ! git diff --cached --quiet; then
            echo "Committing staged metadata files..."
            
            # Build commit message grouped by plugin type
            COMMIT_PARTS=()
            
            if [ -n "$GENERATED_MODELS" ]; then
              COMMIT_PARTS+=("models: $GENERATED_MODELS")
            fi
            
            if [ -n "$GENERATED_BENCHMARKS" ]; then
              COMMIT_PARTS+=("benchmarks: $GENERATED_BENCHMARKS")
            fi
            
            if [ ${#COMMIT_PARTS[@]} -gt 0 ]; then
              COMMIT_MSG="Auto-generate metadata.yml for ${COMMIT_PARTS[0]}"
              # If both types exist, add the second on a new line
              if [ ${#COMMIT_PARTS[@]} -gt 1 ]; then
                COMMIT_MSG="${COMMIT_MSG}"$'\n'"Auto-generate metadata.yml for ${COMMIT_PARTS[1]}"
              fi
            else
              COMMIT_MSG="Auto-generate metadata.yml for new plugins"
            fi
            
            git commit -m "$COMMIT_MSG" || echo "Commit failed"
            
            # Configure git to use token for push (works for same-repo PRs, not fork PRs)
            git remote set-url origin https://x-access-token:${GH_TOKEN}@github.com/${{ github.repository }}.git
            git push origin ${{ github.event.pull_request.head.ref }} || echo "Push failed (may be fork PR or no changes)"
          else
            echo "No metadata files staged for commit"
          fi

  # ============================================================================
  # JOB 5: Layer Mapping (Conditional - only for new models, vision domain only)
  # ============================================================================
  layer_mapping:
    name: "5. Layer Mapping"
    needs: [detect_changes, validate_pr]
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.needs_mapping == 'true' &&
      needs.validate_pr.outputs.all_tests_pass == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Trigger layer mapping
        if: ${{ env.DOMAIN != 'language' }}
        env:
          JENKINS_USER: ${{ secrets.JENKINS_MAPPING_USER }}
          JENKINS_USER_API: ${{ secrets.JENKINS_MAPPING_USER_API }}
          JENKINS_TOKEN: ${{ secrets.JENKINS_MAPPING_TOKEN }}
          JENKINS_TRIGGER: ${{ secrets.JENKINS_MAPPING_URL }}
        run: |
          PLUGIN_INFO_B64='${{ needs.detect_changes.outputs.plugin_info_json }}'
          PLUGIN_INFO=$(echo "$PLUGIN_INFO_B64" | base64 -d)
          NEW_MODELS=$(echo "$PLUGIN_INFO" | jq -r '.new_models // []')
          python brainscore_language/submission/actions_helpers.py trigger_layer_mapping \
            --new-models "$NEW_MODELS" \
            --pr-number ${{ github.event.pull_request.number }} \
            --source-repo ${{ github.event.pull_request.head.repo.clone_url }} \
            --source-branch ${{ github.event.pull_request.head.ref }}

  # ============================================================================
  # JOB 6: Auto-merge (Conditional - only if validated and approved)
  # ============================================================================
  automerge:
    name: "6. Auto-merge"
    needs: [detect_changes, validate_pr, process_metadata, generate_metadata, layer_mapping]
    if: |
      github.event_name == 'pull_request' &&
      needs.validate_pr.outputs.is_automergeable == 'true' &&
      needs.validate_pr.outputs.all_tests_pass == 'true' &&
      (needs.process_metadata.result == 'success' || needs.process_metadata.result == 'skipped') &&
      (needs.generate_metadata.result == 'success' || needs.generate_metadata.result == 'skipped') &&
      (needs.layer_mapping.result == 'success' || needs.layer_mapping.result == 'skipped')
    runs-on: ubuntu-latest
    steps:
      - name: Auto Approve
        uses: hmarr/auto-approve-action@v4
        with:
          pull-request-number: ${{ github.event.pull_request.number }}
          github-token: ${{ secrets.APPROVAL_TOKEN }}

      - name: Check for automerge labels
        id: check_automerge_labels
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          LABELS_JSON=$(gh pr view ${{ github.event.pull_request.number }} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge")' >/dev/null; then
            echo "has_automerge=true" >> $GITHUB_OUTPUT
          else
            echo "has_automerge=false" >> $GITHUB_OUTPUT
          fi
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "has_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "has_automerge_web=false" >> $GITHUB_OUTPUT
          fi

      - name: Auto Merge (GitHub submissions)
        if: steps.check_automerge_labels.outputs.has_automerge == 'true'
        uses: plm9606/automerge_actions@1.2.2
        with:
          github-token: ${{ secrets.WORKFLOW_TOKEN }}
          label-name: "automerge"
          merge-method: "squash"
          auto-delete: "true"

      - name: Auto Merge (brain-score.org submissions)
        if: steps.check_automerge_labels.outputs.has_automerge_web == 'true'
        uses: plm9606/automerge_actions@1.2.2
        with:
          github-token: ${{ secrets.WORKFLOW_TOKEN }}
          label-name: "automerge-web"
          merge-method: "squash"
          auto-delete: "true"

  # ============================================================================
  # JOB 7: Post-Merge Scoring (Runs after PR is merged)
  # ============================================================================
  post_merge_scoring:
    name: "7. Post-Merge Scoring"
    needs: detect_changes
    if: |
      github.event_name == 'pull_request_target' &&
      github.event.pull_request.merged == true &&
      needs.detect_changes.result == 'success' &&
      needs.detect_changes.outputs.needs_scoring == 'true' &&
      needs.detect_changes.outputs.metadata_only == 'false'
    runs-on: ubuntu-latest
    env:
      BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install "."

      - name: Check for automerge-web label
        id: check_automerge_web
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          LABELS_JSON=$(gh pr view ${{ github.event.number }} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "is_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "is_automerge_web=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract user email
        id: extract_email
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
        run: |
          EMAIL=$(python brainscore_language/submission/actions_helpers.py extract_email \
            --pr-username "${{ github.event.pull_request.user.login }}" \
            --pr-title "${{ github.event.pull_request.title }}" \
            --is-automerge-web ${{ steps.check_automerge_web.outputs.is_automerge_web }})
          echo "::add-mask::$EMAIL"
          echo "email=$EMAIL" >> $GITHUB_OUTPUT

      - name: Build plugin info
        id: build_info
        run: |
          PLUGIN_INFO_B64='${{ needs.detect_changes.outputs.plugin_info_json }}'
          PLUGIN_INFO_DECODED=$(echo "$PLUGIN_INFO_B64" | base64 -d)
          PLUGIN_INFO=$(echo "$PLUGIN_INFO_DECODED" | jq -c \
            --arg domain "language" \
            --arg email "${{ steps.extract_email.outputs.email }}" \
            --arg plugin_dirs "${{ needs.detect_changes.outputs.plugin_dirs }}" \
            --arg plugin_type "${{ needs.detect_changes.outputs.plugin_type }}" \
            '. + {
              domain: $domain,
              email: $email,
              plugin_dirs: $plugin_dirs,
              plugin_type: $plugin_type,
              competition: "None",
              model_type: "artificialsubject",
              public: true
            }')
          echo "PLUGIN_INFO=${PLUGIN_INFO}" >> $GITHUB_ENV
          echo "plugin_info=${PLUGIN_INFO}" >> $GITHUB_OUTPUT
          # Mask email in log output (email is already in PLUGIN_INFO JSON)
          PLUGIN_INFO_MASKED=$(echo "$PLUGIN_INFO" | jq -c 'if .email then .email = "***MASKED***" else . end')
          echo "Plugin info (email masked): ${PLUGIN_INFO_MASKED}"

      - name: Trigger Jenkins scoring
        env:
          JENKINS_USER: ${{ secrets.JENKINS_USER }}
          JENKINS_TOKEN: ${{ secrets.JENKINS_TOKEN }}
          JENKINS_TRIGGER: ${{ secrets.JENKINS_TRIGGER }}
          PLUGIN_INFO: ${{ steps.build_info.outputs.plugin_info }}
        run: |
          python -c 'from brainscore_core.submission.endpoints import call_jenkins; import os; call_jenkins(os.environ["PLUGIN_INFO"])'

  # ============================================================================
  # JOB 8: Failure Notification (Runs if any job fails)
  # ============================================================================
  notify_on_failure:
    name: "8. Notify on Failure"
    needs: [detect_changes, validate_pr, layer_mapping, process_metadata, generate_metadata, automerge, post_merge_scoring]
    if: |
      always() && (
        needs.detect_changes.result == 'failure' ||
        needs.validate_pr.result == 'failure' ||
        (needs.validate_pr.result == 'success' && needs.validate_pr.outputs.all_tests_pass == 'false') ||
        needs.layer_mapping.result == 'failure' ||
        needs.process_metadata.result == 'failure' ||
        needs.generate_metadata.result == 'failure' ||
        needs.automerge.result == 'failure' ||
        needs.post_merge_scoring.result == 'failure'
      )
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        if: github.event_name == 'pull_request'
        uses: actions/checkout@v4

      - name: Set up Python
        if: github.event_name == 'pull_request'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        if: github.event_name == 'pull_request'
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install "."

      - name: Determine which job failed
        id: failed_job
        run: |
          if [ "${{ needs.detect_changes.result }}" == "failure" ]; then
            FAILED_JOB="Detect Changes"
          elif [ "${{ needs.validate_pr.result }}" == "failure" ]; then
            FAILED_JOB="Validate PR"
          elif [ "${{ needs.layer_mapping.result }}" == "failure" ]; then
            FAILED_JOB="Layer Mapping"
          elif [ "${{ needs.process_metadata.result }}" == "failure" ]; then
            FAILED_JOB="Update Existing Metadata"
          elif [ "${{ needs.generate_metadata.result }}" == "failure" ]; then
            FAILED_JOB="Generate Metadata"
          elif [ "${{ needs.automerge.result }}" == "failure" ]; then
            FAILED_JOB="Auto-merge"
          elif [ "${{ needs.post_merge_scoring.result }}" == "failure" ]; then
            FAILED_JOB="Post-Merge Scoring"
          else
            FAILED_JOB="Unknown"
          fi
          echo "failed_job=${FAILED_JOB}" >> $GITHUB_OUTPUT
          echo "Failed job: ${FAILED_JOB}"

      - name: Check for automerge-web label
        if: github.event_name == 'pull_request'
        id: check_automerge_web_notify
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          LABELS_JSON=$(gh pr view ${{ github.event.pull_request.number }} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "is_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "is_automerge_web=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract email for notification
        if: github.event_name == 'pull_request'
        id: get_email
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
        run: |
          EMAIL=$(python brainscore_language/submission/actions_helpers.py extract_email \
            --pr-username "${{ github.event.pull_request.user.login }}" \
            --pr-title "${{ github.event.pull_request.title }}" \
            --is-automerge-web ${{ steps.check_automerge_web_notify.outputs.is_automerge_web }} || echo "")
          if [ -z "$EMAIL" ]; then
            echo "Warning: Could not extract email for user ${{ github.event.pull_request.user.login }}"
            echo "email=" >> $GITHUB_OUTPUT
            echo "email_found=false" >> $GITHUB_OUTPUT
          else
            echo "::add-mask::$EMAIL"
            echo "email=$EMAIL" >> $GITHUB_OUTPUT
            echo "email_found=true" >> $GITHUB_OUTPUT
          fi

      - name: Notify user
        if: |
          github.event_name == 'pull_request' &&
          steps.get_email.outputs.email_found == 'true'
        env:
          GMAIL_USERNAME: ${{ secrets.GMAIL_USERNAME }}
          GMAIL_PASSWORD: ${{ secrets.GMAIL_PASSWORD }}
        run: |
          python brainscore_language/submission/actions_helpers.py send_failure_email \
            "${{ steps.get_email.outputs.email }}" \
            "${{ github.event.pull_request.number }}" \
            "${{ steps.failed_job.outputs.failed_job }}" \
            "$GMAIL_USERNAME" \
            "$GMAIL_PASSWORD"
      
      - name: Log email extraction failure
        if: |
          github.event_name == 'pull_request' &&
          steps.get_email.outputs.email_found == 'false'
        run: |
          echo "Could not send failure notification email - email not found for user ${{ github.event.pull_request.user.login }}"
          echo "Failure reason: ${{ steps.failed_job.outputs.failed_job }}"
          echo "PR: https://github.com/${{ github.repository }}/pull/${{ github.event.pull_request.number }}"