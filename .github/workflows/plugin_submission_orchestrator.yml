name: Plugin Submission Orchestrator

# Combined workflow: Handles both prepare (metadata generation/updates) and validate (downstream validation, automerge, scoring)
# This workflow combines the prepare and validate workflows into a single unified workflow

on:
  pull_request:
    types: [opened, synchronize, labeled]
  pull_request_target:
    types: [closed]
    branches: [main]

permissions:
  contents: write
  pull-requests: write
  issues: write
  checks: read
  statuses: read

env:
  DOMAIN: language
  DOMAIN_ROOT: brainscore_language
  PYTHON_VERSION: '3.11'

jobs:
  # ============================================================================
  # JOB 1: Detect and Classify Changes
  # ============================================================================
  detect_changes:
    name: "1. Detect Changes"
    runs-on: ubuntu-latest
    outputs:
      has_plugins: ${{ steps.detect.outputs.has_plugins }}
      plugin_type: ${{ steps.detect.outputs.plugin_type }}
      plugin_dirs: ${{ steps.detect.outputs.plugin_dirs }}
      has_new_models: ${{ steps.detect.outputs.has_new_models }}
      metadata_only: ${{ steps.detect.outputs.metadata_only }}
      needs_scoring: ${{ steps.detect.outputs.needs_scoring }}
      needs_mapping: ${{ steps.detect.outputs.needs_mapping }}
      needs_metadata_generation: ${{ steps.detect.outputs.needs_metadata_generation }}
      is_automergeable: ${{ steps.detect.outputs.is_automergeable }}
      plugin_info_json: ${{ steps.detect.outputs.plugin_info_json }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.ref || '' }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Get changed files
        id: changed_files
        run: |
          if [ "${{ github.event_name }}" == "pull_request_target" ] && [ "${{ github.event.pull_request.merged }}" == "true" ]; then
            # Post-merge: compare merge commit to previous
            git fetch origin refs/pull/${{ github.event.number }}/head
            MERGE_COMMIT=$(git log --format='%H %P' --all | grep "$(git rev-parse FETCH_HEAD)$" | cut -f1 -d' ')
            CHANGED_FILES=$(git diff --name-only origin/main~1 $MERGE_COMMIT | tr '\n' ' ' || echo "")
          else
            # Pre-merge: use GitHub API to get changed files (more reliable than git diff)
            PR_NUMBER="${{ github.event.pull_request.number }}"
            CHANGED_FILES=$(gh pr view ${PR_NUMBER} --json files --jq '.files[].path' | tr '\n' ' ' || echo "")
            
            # Fallback to git diff if API fails or returns empty
            if [ -z "$CHANGED_FILES" ] || [ "$CHANGED_FILES" = " " ]; then
              echo "GitHub API returned no files, trying git diff fallback..."
              BASE_REF="${{ github.event.pull_request.base.ref }}"
              BASE_SHA="${{ github.event.pull_request.base.sha }}"
              HEAD_SHA="${{ github.event.pull_request.head.sha }}"
              
              git fetch origin ${BASE_REF} || true
              git fetch origin ${HEAD_SHA} || true
              
              if [ -n "$BASE_SHA" ] && [ -n "$HEAD_SHA" ]; then
                CHANGED_FILES=$(git diff --name-only ${BASE_SHA}...${HEAD_SHA} | tr '\n' ' ' || echo "")
              fi
              
              if [ -z "$CHANGED_FILES" ] || [ "$CHANGED_FILES" = " " ]; then
                CHANGED_FILES=$(git diff --name-only origin/${BASE_REF}...HEAD | tr '\n' ' ' || echo "")
              fi
            fi
          fi
          echo "CHANGED_FILES=${CHANGED_FILES}" >> $GITHUB_ENV
          echo "Changed files: ${CHANGED_FILES}"
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}

      - name: Detect plugin changes
        id: detect
        run: |
          CHANGED_FILES="${{ env.CHANGED_FILES }}"
          if [ -z "$CHANGED_FILES" ]; then
            echo "No changed files detected, using empty string"
            CHANGED_FILES=""
          fi
          
          CHANGED_FILES_B64=$(echo -n "${CHANGED_FILES}" | base64 | tr -d '\n')
          PLUGIN_INFO=$(python -W ignore -c "
          from brainscore_core.plugin_management.parse_plugin_changes import get_scoring_info
          import json
          import sys
          import base64
          try:
              changed_files_b64 = '${CHANGED_FILES_B64}'
              changed_files = base64.b64decode(changed_files_b64).decode('utf-8') if changed_files_b64 else ''
              get_scoring_info(changed_files, '${{ env.DOMAIN_ROOT }}')
          except Exception as e:
              error_msg = f'Error in get_scoring_info: {type(e).__name__}: {str(e)}'
              print(error_msg, file=sys.stderr)
              print('{}')
          " 2>&1 | grep -v "^Error in get_scoring_info" | grep -v "^Warning:" | jq -c . 2>/dev/null | tail -n 1 || echo '{}')
          
          if ! echo "$PLUGIN_INFO" | jq empty 2>/dev/null; then
            echo "Warning: Invalid JSON from get_scoring_info, using empty object"
            PLUGIN_INFO='{}'
          fi
          
          echo "PLUGIN_INFO=${PLUGIN_INFO}" >> $GITHUB_ENV
          
          HAS_PLUGINS_RAW=$(echo "$PLUGIN_INFO" | jq -r 'if .modifies_plugins == true then "true" else "false" end' | head -n 1)
          HAS_PLUGINS=$(echo "$HAS_PLUGINS_RAW" | tr '[:upper:]' '[:lower:]')
          
          # Infer plugin_type from changed_plugins structure
          HAS_MODELS=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.models // [] | length' | head -n 1)
          HAS_BENCHMARKS=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.benchmarks // [] | length' | head -n 1)
          PLUGIN_TYPE=""
          if [ "$HAS_MODELS" -gt 0 ] 2>/dev/null && [ "$HAS_BENCHMARKS" -gt 0 ] 2>/dev/null; then
            PLUGIN_TYPE="models,benchmarks"
          elif [ "$HAS_MODELS" -gt 0 ] 2>/dev/null; then
            PLUGIN_TYPE="models"
          elif [ "$HAS_BENCHMARKS" -gt 0 ] 2>/dev/null; then
            PLUGIN_TYPE="benchmarks"
          fi
          
          NEEDS_SCORING_RAW=$(echo "$PLUGIN_INFO" | jq -r '.run_score // "False"' | head -n 1)
          NEEDS_SCORING=$(echo "$NEEDS_SCORING_RAW" | tr '[:upper:]' '[:lower:]')
          IS_AUTOMERGEABLE_RAW=$(echo "$PLUGIN_INFO" | jq -r 'if .is_automergeable == true then "true" else "false" end' | head -n 1)
          IS_AUTOMERGEABLE=$(echo "$IS_AUTOMERGEABLE_RAW" | tr '[:upper:]' '[:lower:]')
          
          # Check if new_models string exists and is non-empty (it's a space-separated string, not an array)
          # get_scoring_info sets new_models to a space-separated string of plugin IDs found in __init__.py files
          NEW_MODELS=$(echo "$PLUGIN_INFO" | jq -r '.new_models // ""' | head -n 1)
          # Debug: show what new_models contains
          echo "DEBUG: new_models value from JSON: '${NEW_MODELS}'"
          
          # Check if we have models in changed_plugins (this is more reliable than new_models)
          MODELS_COUNT=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.models // [] | length' | head -n 1)
          echo "DEBUG: changed_plugins.models count: ${MODELS_COUNT}"
          
          # Set has_new_models based on whether we have models in changed_plugins
          # This is more reliable than relying on new_models which depends on get_plugin_ids finding registry entries
          if [ -n "$MODELS_COUNT" ] && [ "$MODELS_COUNT" != "null" ] && [ "$MODELS_COUNT" != "0" ]; then
            HAS_NEW_MODELS="true"
            echo "DEBUG: Found ${MODELS_COUNT} model(s) in changed_plugins.models - setting has_new_models=true"
          elif [ -n "$NEW_MODELS" ] && [ "$NEW_MODELS" != "null" ] && [ "$NEW_MODELS" != "" ]; then
            HAS_NEW_MODELS="true"
            echo "DEBUG: new_models contains: '${NEW_MODELS}' - setting has_new_models=true"
          else
            HAS_NEW_MODELS="false"
            echo "DEBUG: No models found - setting has_new_models=false"
          fi
          
          MODELS=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.models[]? // empty' | head -n 1)
          BENCHMARKS=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.benchmarks[]? // empty' | head -n 1)
          PLUGIN_DIRS=""
          if [ -n "$MODELS" ]; then
            for model in $(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.models[]? // empty'); do
              if [ -n "$model" ]; then
                if [ -z "$PLUGIN_DIRS" ]; then
                  PLUGIN_DIRS="${DOMAIN_ROOT}/models/${model}"
                else
                  PLUGIN_DIRS="${PLUGIN_DIRS},${DOMAIN_ROOT}/models/${model}"
                fi
              fi
            done
          fi
          if [ -n "$BENCHMARKS" ]; then
            for benchmark in $(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.benchmarks[]? // empty'); do
              if [ -n "$benchmark" ]; then
                if [ -z "$PLUGIN_DIRS" ]; then
                  PLUGIN_DIRS="${DOMAIN_ROOT}/benchmarks/${benchmark}"
                else
                  PLUGIN_DIRS="${PLUGIN_DIRS},${DOMAIN_ROOT}/benchmarks/${benchmark}"
                fi
              fi
            done
          fi
          
          NON_METADATA=$(echo "$CHANGED_FILES" | tr ' ' '\n' | grep -Ev "metadata\.ya?ml" || true)
          METADATA_ONLY="false"
          if [ -z "$NON_METADATA" ] && [ "$HAS_PLUGINS" = "true" ]; then
            METADATA_ONLY="true"
          fi
          
          NEEDS_MAPPING="false"
          if [ "$DOMAIN" != "language" ] && [ "$HAS_NEW_MODELS" = "true" ] && [ "$NEEDS_SCORING" = "true" ]; then
            NEEDS_MAPPING="true"
          fi
          
          NEEDS_METADATA_GENERATION="false"
          MISSING_METADATA_DIRS=()
          if [ "$HAS_PLUGINS" = "true" ] && [ "$METADATA_ONLY" = "false" ]; then
            IFS=',' read -ra DIRS <<< "$PLUGIN_DIRS"
            for dir in "${DIRS[@]}"; do
              if [ -n "$dir" ]; then
                if [ ! -f "${dir}/metadata.yml" ] && [ ! -f "${dir}/metadata.yaml" ]; then
                  NEEDS_METADATA_GENERATION="true"
                  MISSING_METADATA_DIRS+=("${dir}")
                  echo "Plugin directory missing metadata: ${dir}"
                fi
              fi
            done
          fi
          
          echo "has_plugins=${HAS_PLUGINS:-false}" >> $GITHUB_OUTPUT
          echo "plugin_type=${PLUGIN_TYPE:-}" >> $GITHUB_OUTPUT
          echo "plugin_dirs=${PLUGIN_DIRS:-}" >> $GITHUB_OUTPUT
          echo "has_new_models=${HAS_NEW_MODELS:-false}" >> $GITHUB_OUTPUT
          echo "metadata_only=${METADATA_ONLY:-false}" >> $GITHUB_OUTPUT
          echo "needs_scoring=${NEEDS_SCORING:-false}" >> $GITHUB_OUTPUT
          echo "needs_mapping=${NEEDS_MAPPING:-false}" >> $GITHUB_OUTPUT
          echo "needs_metadata_generation=${NEEDS_METADATA_GENERATION:-false}" >> $GITHUB_OUTPUT
          echo "is_automergeable=${IS_AUTOMERGEABLE:-false}" >> $GITHUB_OUTPUT
          if [ -n "$PLUGIN_INFO" ]; then
            PLUGIN_INFO_B64=$(echo "$PLUGIN_INFO" | base64 | tr -d '\n')
            echo "plugin_info_json=${PLUGIN_INFO_B64}" >> $GITHUB_OUTPUT
          else
            echo "plugin_info_json=" >> $GITHUB_OUTPUT
          fi
          
          echo "Detection results:"
          echo "  Has plugins: ${HAS_PLUGINS}"
          echo "  Plugin type: ${PLUGIN_TYPE}"
          echo "  Plugin dirs: ${PLUGIN_DIRS}"
          echo "  Has new models: ${HAS_NEW_MODELS}"
          echo "  Metadata only: ${METADATA_ONLY}"
          echo "  Needs scoring: ${NEEDS_SCORING}"
          echo "  Needs mapping: ${NEEDS_MAPPING}"
          echo "  Needs metadata generation: ${NEEDS_METADATA_GENERATION}"
          if [ "${#MISSING_METADATA_DIRS[@]}" -gt 0 ]; then
            echo "  Plugins missing metadata: ${MISSING_METADATA_DIRS[*]}"
          fi
          echo "  Is automergeable: ${IS_AUTOMERGEABLE}"
          echo "  Changed files: ${CHANGED_FILES}"

  # ============================================================================
  # JOB 2: Validate PR (Minimal validation to proceed with mutation)
  # ============================================================================
  validate_pr:
    name: "2. Validate PR"
    needs: detect_changes
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.has_plugins == 'true'
    runs-on: ubuntu-latest
    outputs:
      is_automergeable: ${{ steps.validate.outputs.is_automergeable }}
      all_tests_pass: ${{ steps.validate.outputs.all_tests_pass }}
      pr_number: ${{ steps.get_pr_info.outputs.pr_number }}
      is_automerge_web: ${{ steps.check_label.outputs.is_automerge_web }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Get PR number and latest head SHA
        id: get_pr_info
        run: |
          echo "pr_number=${{ github.event.pull_request.number }}" >> $GITHUB_OUTPUT
          # Get the latest commit SHA from the checked-out branch (after any mutations)
          PR_HEAD_SHA=$(git rev-parse HEAD)
          echo "pr_head_sha=${PR_HEAD_SHA}" >> $GITHUB_OUTPUT
          echo "PR head SHA: ${PR_HEAD_SHA}"

      - name: Check for automerge-web label
        id: check_label
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          LABELS_JSON=$(gh pr view ${{ steps.get_pr_info.outputs.pr_number }} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "is_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "is_automerge_web=false" >> $GITHUB_OUTPUT
          fi

      - name: Validate PR
        id: validate
        run: |
          RESULT=$(python brainscore_language/submission/actions_helpers.py validate_pr \
            --pr-number ${{ steps.get_pr_info.outputs.pr_number }} \
            --pr-head ${{ steps.get_pr_info.outputs.pr_head_sha }} \
            --is-automerge-web ${{ steps.check_label.outputs.is_automerge_web }})
          
          IS_AUTOMERGEABLE=$(echo "$RESULT" | jq -r '.is_automergeable // false' | head -n 1)
          ALL_TESTS_PASS=$(echo "$RESULT" | jq -r '.all_tests_pass // false' | head -n 1)
          
          echo "is_automergeable=${IS_AUTOMERGEABLE}" >> $GITHUB_OUTPUT
          echo "all_tests_pass=${ALL_TESTS_PASS}" >> $GITHUB_OUTPUT
          
          echo "Validation results:"
          echo "  Is automergeable: ${IS_AUTOMERGEABLE}"
          echo "  All tests pass: ${ALL_TESTS_PASS}"

      - name: Check for submission_prepared label
        id: check_submission_prepared
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          LABELS_JSON=$(gh pr view ${{ steps.get_pr_info.outputs.pr_number }} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "submission_prepared")' >/dev/null; then
            echo "has_submission_prepared=true" >> $GITHUB_OUTPUT
          else
            echo "has_submission_prepared=false" >> $GITHUB_OUTPUT
          fi

      - name: Add submission_validated label if tests pass and submission_prepared exists
        if: |
          steps.validate.outputs.all_tests_pass == 'true' &&
          steps.check_submission_prepared.outputs.has_submission_prepared == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          PR_NUM="${{ steps.get_pr_info.outputs.pr_number }}"
          LABELS_JSON=$(gh pr view ${PR_NUM} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "submission_validated")' >/dev/null; then
            echo "submission_validated label already exists on PR, skipping"
          else
            gh pr edit ${PR_NUM} --add-label "submission_validated"
            echo "Added 'submission_validated' label to PR (tests passed and submission_prepared exists)"
          fi

      - name: Add submission_validation_failure label if tests fail and submission_prepared exists
        if: |
          steps.validate.outputs.all_tests_pass == 'false' &&
          steps.check_submission_prepared.outputs.has_submission_prepared == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          gh pr edit ${{ steps.get_pr_info.outputs.pr_number }} --add-label "submission_validation_failure" || echo "Failed to add submission_validation_failure label (may already exist on PR)"
          echo "Added 'submission_validation_failure' label to PR"

  # ============================================================================
  # JOB 3: Handle Metadata-Only PRs (Add label and terminate)
  # ============================================================================
  handle_metadata_only:
    name: "3. Handle Metadata-Only PR"
    needs: [detect_changes, validate_pr]
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.metadata_only == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Add labels
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          gh pr edit ${{ github.event.pull_request.number }} --add-label "only_update_metadata" || echo "Failed to add only_update_metadata label (may already exist on PR)"
          gh pr edit ${{ github.event.pull_request.number }} --add-label "submission_prepared" || echo "Failed to add submission_prepared label (may already exist on PR)"
          echo "Added 'only_update_metadata' and 'submission_prepared' labels to PR"
      
      - name: Add submission_validated label if tests passed (metadata-only PRs)
        if: needs.validate_pr.outputs.all_tests_pass == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          PR_NUM="${{ github.event.pull_request.number }}"
          LABELS_JSON=$(gh pr view ${PR_NUM} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "submission_validated")' >/dev/null; then
            echo "submission_validated label already exists on PR, skipping"
          else
            gh pr edit ${PR_NUM} --add-label "submission_validated"
            echo "Added 'submission_validated' label to PR (tests passed for metadata-only PR)"
          fi
      
      - name: Add submission_validation_failure label if tests failed (metadata-only PRs)
        if: needs.validate_pr.outputs.all_tests_pass == 'false'
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          gh pr edit ${{ github.event.pull_request.number }} --add-label "submission_validation_failure" || echo "Failed to add submission_validation_failure label (may already exist on PR)"
          echo "Added 'submission_validation_failure' label to PR (tests failed for metadata-only PR)"
      
      - name: Add submission_preparation_failure label on job failure
        if: failure()
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          gh pr edit ${{ github.event.pull_request.number }} --add-label "submission_preparation_failure" || echo "Failed to add submission_preparation_failure label"
          echo "Added 'submission_preparation_failure' label due to job failure"

  # ============================================================================
  # JOB 4: Generate Mutations and Commit (Metadata Generation + Layer Mapping)
  # All steps run in the same job so staged files persist across steps
  # ============================================================================
  generate_and_commit_mutations:
    name: "4. Generate Mutations and Commit"
    needs: [detect_changes, validate_pr]
    if: |
      github.event_name == 'pull_request' &&
      (
        (needs.detect_changes.outputs.needs_metadata_generation == 'true' && needs.validate_pr.outputs.all_tests_pass == 'true') ||
        (needs.detect_changes.outputs.needs_mapping == 'true' && needs.validate_pr.outputs.all_tests_pass == 'true')
      )
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: "us-east-1"

      - name: Configure Git
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      # Step 4: Generate Metadata (stages files)
      - name: Generate metadata for plugins
        id: generate_metadata
        if: needs.detect_changes.outputs.needs_metadata_generation == 'true'
        env:
          BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
        run: |
          IFS=',' read -ra PLUGIN_DIRS <<< "${{ needs.detect_changes.outputs.plugin_dirs }}"
          
          GENERATED_MODELS=()
          GENERATED_BENCHMARKS=()
          
          for dir in "${PLUGIN_DIRS[@]}"; do
            if [ -n "$dir" ]; then
              if [[ "$dir" == *"/models/"* ]]; then
                PLUGIN_TYPE="models"
              elif [[ "$dir" == *"/benchmarks/"* ]]; then
                PLUGIN_TYPE="benchmarks"
              else
                echo "Could not determine plugin type for ${dir}, skipping"
                continue
              fi
              
              PLUGIN_NAME=$(basename "$dir")
              
              if [ ! -f "${dir}/metadata.yml" ] && [ ! -f "${dir}/metadata.yaml" ]; then
                echo "Generating metadata for: ${dir} (type: ${PLUGIN_TYPE})"
                
                if python brainscore_language/submission/hardcoded_metadata.py "${dir}" "${PLUGIN_TYPE}"; then
                  if [ -f "${dir}/metadata.yml" ]; then
                    git add "${dir}/metadata.yml"
                    echo "Staged ${dir}/metadata.yml"
                  elif [ -f "${dir}/metadata.yaml" ]; then
                    git add "${dir}/metadata.yaml"
                    echo "Staged ${dir}/metadata.yaml"
                  fi
                  if [ "$PLUGIN_TYPE" == "models" ]; then
                    GENERATED_MODELS+=("${PLUGIN_NAME}")
                  else
                    GENERATED_BENCHMARKS+=("${PLUGIN_NAME}")
                  fi
                else
                  echo "Metadata generation failed for ${dir}, continuing..."
                fi
              else
                echo "Metadata already exists for: ${dir}, skipping generation"
              fi
            fi
          done
          
          # Store generated plugin names for commit message
          if [ ${#GENERATED_MODELS[@]} -gt 0 ]; then
            GENERATED_MODELS_STR=$(IFS=','; echo "${GENERATED_MODELS[*]}")
            echo "GENERATED_MODELS=${GENERATED_MODELS_STR}" >> $GITHUB_ENV
            echo "generated_models=${GENERATED_MODELS_STR}" >> $GITHUB_OUTPUT
          fi
          if [ ${#GENERATED_BENCHMARKS[@]} -gt 0 ]; then
            GENERATED_BENCHMARKS_STR=$(IFS=','; echo "${GENERATED_BENCHMARKS[*]}")
            echo "GENERATED_BENCHMARKS=${GENERATED_BENCHMARKS_STR}" >> $GITHUB_ENV
            echo "generated_benchmarks=${GENERATED_BENCHMARKS_STR}" >> $GITHUB_OUTPUT
          fi

      # Step 5: Layer Mapping (stages files)
      - name: Trigger layer mapping
        id: layer_mapping
        if: |
          needs.detect_changes.outputs.needs_mapping == 'true' &&
          env.DOMAIN != 'language'
        env:
          JENKINS_USER: ${{ secrets.JENKINS_MAPPING_USER }}
          JENKINS_USER_API: ${{ secrets.JENKINS_MAPPING_USER_API }}
          JENKINS_TOKEN: ${{ secrets.JENKINS_MAPPING_TOKEN }}
          JENKINS_TRIGGER: ${{ secrets.JENKINS_MAPPING_URL }}
        run: |
          PLUGIN_INFO_B64='${{ needs.detect_changes.outputs.plugin_info_json }}'
          PLUGIN_INFO=$(echo "$PLUGIN_INFO_B64" | base64 -d)
          NEW_MODELS=$(echo "$PLUGIN_INFO" | jq -r '.new_models // []')
          python brainscore_language/submission/actions_helpers.py trigger_layer_mapping \
            --new-models "$NEW_MODELS" \
            --pr-number ${{ github.event.pull_request.number }} \
            --source-repo ${{ github.event.pull_request.head.repo.clone_url }} \
            --source-branch ${{ github.event.pull_request.head.ref }}
          
          # Stage any layer mapping files that were generated
          if [ -n "$(git status --porcelain)" ]; then
            git add -A
            echo "Staged layer mapping files"
          fi

      # Step 6: Commit and Push (commits all staged files from steps 4 and 5)
      - name: Commit and push all mutations
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          # Commit all staged changes (metadata from step 4 + layer mapping from step 5)
          # Staged files persist across steps within the same job
          if ! git diff --cached --quiet; then
            echo "Committing all mutations (metadata generation and/or layer mapping)..."
            
            # Build commit message
            COMMIT_PARTS=()
            if [ "${{ steps.generate_metadata.outputs.generated_models }}" ] || [ "${{ steps.generate_metadata.outputs.generated_benchmarks }}" ]; then
              GENERATED_MODELS="${{ steps.generate_metadata.outputs.generated_models }}"
              GENERATED_BENCHMARKS="${{ steps.generate_metadata.outputs.generated_benchmarks }}"
              if [ -n "$GENERATED_MODELS" ] && [ -n "$GENERATED_BENCHMARKS" ]; then
                COMMIT_PARTS+=("metadata generation: models ($GENERATED_MODELS), benchmarks ($GENERATED_BENCHMARKS)")
              elif [ -n "$GENERATED_MODELS" ]; then
                COMMIT_PARTS+=("metadata generation: models ($GENERATED_MODELS)")
              elif [ -n "$GENERATED_BENCHMARKS" ]; then
                COMMIT_PARTS+=("metadata generation: benchmarks ($GENERATED_BENCHMARKS)")
              else
                COMMIT_PARTS+=("metadata generation")
              fi
            fi
            if [ "${{ steps.layer_mapping.outcome }}" == "success" ]; then
              COMMIT_PARTS+=("layer mapping")
            fi
            
            COMMIT_MSG="Auto-generate: $(IFS=', '; echo "${COMMIT_PARTS[*]}")"
            
            git commit -m "$COMMIT_MSG" || echo "Commit failed (may be no changes)"
            
            # Use PAT for push (required to trigger workflows)
            echo "Using PAT for push and PR operations"
            PUSH_TOKEN="$GH_TOKEN"
            # Set remote URL with token (GitHub Actions automatically masks secrets in logs)
            git remote set-url origin https://x-access-token:${PUSH_TOKEN}@github.com/${{ github.repository }}.git
            # Push and capture exit code without exposing token in error output
            if git push origin ${{ github.event.pull_request.head.ref }} >/dev/null 2>&1; then
              echo "Successfully pushed mutations to PR branch"
              
              # Add submission_prepared label to PR (using PAT)
              echo "Adding submission_prepared label to PR"
              gh pr edit ${{ github.event.pull_request.number }} --add-label "submission_prepared" || echo "Failed to add label (may already exist on PR)"
            else
              echo "Push failed - this may prevent workflow rerun. Check if PAT is configured correctly."
              # Add submission_preparation_failure label on failure
              gh pr edit ${{ github.event.pull_request.number }} --add-label "submission_preparation_failure" || echo "Failed to add submission_preparation_failure label"
              exit 1
            fi
          else
            echo "No staged changes to commit"
            # If no changes were staged, still add submission_prepared label (metadata might already exist)
            echo "No changes to commit, but adding submission_prepared label"
            gh pr edit ${{ github.event.pull_request.number }} --add-label "submission_prepared" || echo "Failed to add label (may already exist on PR)"
          fi
      
      - name: Add submission_preparation_failure label on job failure
        if: failure()
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          gh pr edit ${{ github.event.pull_request.number }} --add-label "submission_preparation_failure" || echo "Failed to add submission_preparation_failure label"
          echo "Added 'submission_preparation_failure' label due to job failure"

  # ============================================================================
  # JOB 5: Update Existing Metadata (Conditional - only if only_update_metadata label present)
  # ============================================================================
  update_existing_metadata:
    name: "5. Update Existing Metadata"
    needs: [detect_changes, validate_pr, handle_metadata_only, generate_and_commit_mutations]
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.metadata_only == 'true' &&
      (needs.handle_metadata_only.result == 'success' || needs.handle_metadata_only.result == 'skipped')
    runs-on: ubuntu-latest
    steps:
      - name: Check for only_update_metadata label
        id: check_label
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          PR_NUM="${{ needs.validate_pr.outputs.pr_number }}"
          LABELS_JSON=$(gh pr view ${PR_NUM} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "only_update_metadata")' >/dev/null; then
            echo "has_label=true" >> $GITHUB_OUTPUT
          else
            echo "has_label=false" >> $GITHUB_OUTPUT
            echo "Error: only_update_metadata label not found on PR"
            exit 1
          fi

      - name: Set up Python
        if: steps.check_label.outputs.has_label == 'true'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        if: steps.check_label.outputs.has_label == 'true'
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install "."

      - name: Trigger update_existing_metadata Jenkins job
        if: steps.check_label.outputs.has_label == 'true'
        env:
          JENKINS_USER: ${{ secrets.JENKINS_USER }}
          JENKINS_TOKEN: ${{ secrets.JENKINS_TOKEN }}
          JENKINS_TRIGGER: ${{ secrets.JENKINS_TRIGGER }}
        run: |
          python brainscore_language/submission/actions_helpers.py trigger_update_existing_metadata \
            --plugin-dirs "${{ needs.detect_changes.outputs.plugin_dirs }}" \
            --plugin-type "${{ needs.detect_changes.outputs.plugin_type }}" \
            --domain "${{ env.DOMAIN }}"

  # ============================================================================
  # JOB 6: Auto-merge (Conditional - only if validated and approved)
  # ============================================================================
  automerge:
    name: "6. Auto-merge"
    needs: [detect_changes, validate_pr, update_existing_metadata, generate_and_commit_mutations]
    if: |
      always() &&
      github.event_name == 'pull_request' &&
      needs.validate_pr.outputs.is_automergeable == 'true' &&
      needs.validate_pr.outputs.all_tests_pass == 'true' &&
      (
        needs.update_existing_metadata.result == 'success' || 
        needs.update_existing_metadata.result == 'skipped' ||
        needs.detect_changes.outputs.metadata_only != 'true'
      ) &&
      (
        needs.generate_and_commit_mutations.result == 'success' || 
        needs.generate_and_commit_mutations.result == 'skipped' ||
        (needs.detect_changes.outputs.needs_metadata_generation != 'true' && needs.detect_changes.outputs.needs_mapping != 'true')
      )
    runs-on: ubuntu-latest
    steps:
      - name: Debug automerge conditions
        run: |
          echo "Event name: ${{ github.event_name }}"
          echo "is_automergeable: ${{ needs.validate_pr.outputs.is_automergeable }}"
          echo "all_tests_pass: ${{ needs.validate_pr.outputs.all_tests_pass }}"
          echo "update_existing_metadata.result: ${{ needs.update_existing_metadata.result }}"
          echo "generate_and_commit_mutations.result: ${{ needs.generate_and_commit_mutations.result }}"
          echo "PR number: ${{ needs.validate_pr.outputs.pr_number }}"

      - name: Auto Approve
        uses: hmarr/auto-approve-action@v4
        with:
          pull-request-number: ${{ needs.validate_pr.outputs.pr_number }}
          github-token: ${{ secrets.APPROVAL_TOKEN }}

      - name: Check for submission_validated label
        id: check_submission_validated
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          PR_NUM="${{ needs.validate_pr.outputs.pr_number }}"
          LABELS_JSON=$(gh pr view ${PR_NUM} --json labels)
          echo "PR labels: $LABELS_JSON"
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "submission_validated")' >/dev/null; then
            echo "has_submission_validated=true" >> $GITHUB_OUTPUT
            echo "Found submission_validated label"
          else
            echo "has_submission_validated=false" >> $GITHUB_OUTPUT
            echo "submission_validated label not found"
          fi
          # Still check for automerge-web for email extraction purposes
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "has_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "has_automerge_web=false" >> $GITHUB_OUTPUT
          fi

      - name: Auto Merge
        if: steps.check_submission_validated.outputs.has_submission_validated == 'true'
        uses: plm9606/automerge_actions@1.2.2
        with:
          github-token: ${{ secrets.WORKFLOW_TOKEN }}
          label-name: "submission_validated"
          merge-method: "squash"
          auto-delete: "true"

  # ============================================================================
  # JOB 7: Post-Merge Scoring (Runs after PR is merged)
  # ============================================================================
  post_merge_scoring:
    name: "7. Post-Merge Scoring"
    needs: detect_changes
    if: |
      github.event_name == 'pull_request_target' &&
      github.event.pull_request.merged == true &&
      needs.detect_changes.result == 'success' &&
      needs.detect_changes.outputs.needs_scoring == 'true' &&
      needs.detect_changes.outputs.metadata_only == 'false'
    runs-on: ubuntu-latest
    env:
      BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install "."

      - name: Check for automerge-web label
        id: check_automerge_web
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          LABELS_JSON=$(gh pr view ${{ github.event.number }} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "is_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "is_automerge_web=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract user email
        id: extract_email
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
        run: |
          EMAIL=$(python brainscore_language/submission/actions_helpers.py extract_email \
            --pr-username "${{ github.event.pull_request.user.login }}" \
            --pr-title "${{ github.event.pull_request.title }}" \
            --is-automerge-web ${{ steps.check_automerge_web.outputs.is_automerge_web }})
          echo "::add-mask::$EMAIL"
          echo "email=$EMAIL" >> $GITHUB_OUTPUT

      - name: Build plugin info
        id: build_info
        run: |
          PLUGIN_INFO_B64='${{ needs.detect_changes.outputs.plugin_info_json }}'
          PLUGIN_INFO_DECODED=$(echo "$PLUGIN_INFO_B64" | base64 -d)
          PLUGIN_INFO=$(echo "$PLUGIN_INFO_DECODED" | jq -c \
            --arg domain "language" \
            --arg email "${{ steps.extract_email.outputs.email }}" \
            --arg plugin_dirs "${{ needs.detect_changes.outputs.plugin_dirs }}" \
            --arg plugin_type "${{ needs.detect_changes.outputs.plugin_type }}" \
            '. + {
              domain: $domain,
              email: $email,
              plugin_dirs: $plugin_dirs,
              plugin_type: $plugin_type,
              competition: "None",
              model_type: "artificialsubject",
              public: true
            }')
          # Store PLUGIN_INFO in GITHUB_ENV for next step (contains email - will be masked by GitHub Actions)
          echo "PLUGIN_INFO=${PLUGIN_INFO}" >> $GITHUB_ENV
          echo "plugin_info=${PLUGIN_INFO}" >> $GITHUB_OUTPUT
          # Mask email and other sensitive fields in log output
          PLUGIN_INFO_MASKED=$(echo "$PLUGIN_INFO" | jq -c 'if .email then .email = "***MASKED***" else . end | if .BSC_DATABASESECRET then .BSC_DATABASESECRET = "***MASKED***" else . end' 2>/dev/null || echo "{}")
          echo "Plugin info (sensitive data masked): ${PLUGIN_INFO_MASKED}"

      - name: Trigger Jenkins scoring
        env:
          JENKINS_USER: ${{ secrets.JENKINS_USER }}
          JENKINS_TOKEN: ${{ secrets.JENKINS_TOKEN }}
          JENKINS_TRIGGER: ${{ secrets.JENKINS_TRIGGER }}
          PLUGIN_INFO: ${{ steps.build_info.outputs.plugin_info }}
        run: |
          # PLUGIN_INFO contains email - GitHub Actions automatically masks secrets in logs
          # Suppress stdout/stderr to prevent any potential exposure of PLUGIN_INFO content
          python -c 'from brainscore_core.submission.endpoints import call_jenkins; import os; call_jenkins(os.environ["PLUGIN_INFO"])' >/dev/null 2>&1 || {
            echo "Jenkins scoring trigger failed (check Jenkins logs for details)"
            exit 1
          }
          echo "Jenkins scoring job triggered successfully"

  # ============================================================================
  # JOB 8: Failure Notification (Runs if any job fails)
  # ============================================================================
  notify_on_failure:
    name: "8. Notify on Failure"
    needs: [detect_changes, validate_pr, handle_metadata_only, generate_and_commit_mutations, update_existing_metadata, automerge, post_merge_scoring]
    if: |
      always() && (
        (needs.detect_changes.result == 'failure') ||
        (needs.validate_pr.result == 'failure') ||
        (needs.validate_pr.result == 'success' && needs.validate_pr.outputs.all_tests_pass == 'false') ||
        (needs.handle_metadata_only.result == 'failure') ||
        (needs.generate_and_commit_mutations.result == 'failure') ||
        (needs.update_existing_metadata.result == 'failure') ||
        (needs.automerge.result == 'failure') ||
        (needs.post_merge_scoring.result == 'failure')
      )
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        if: github.event_name == 'pull_request'
        uses: actions/checkout@v4

      - name: Set up Python
        if: github.event_name == 'pull_request'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        if: github.event_name == 'pull_request'
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install "."

      - name: Determine which job failed
        id: failed_job
        run: |
          if [ "${{ needs.detect_changes.result }}" == "failure" ]; then
            FAILED_JOB="Detect Changes"
          elif [ "${{ needs.validate_pr.result }}" == "failure" ]; then
            FAILED_JOB="Validate PR"
          elif [ "${{ needs.handle_metadata_only.result }}" == "failure" ]; then
            FAILED_JOB="Handle Metadata-Only PR"
          elif [ "${{ needs.generate_and_commit_mutations.result }}" == "failure" ]; then
            FAILED_JOB="Generate Mutations and Commit"
          elif [ "${{ needs.update_existing_metadata.result }}" == "failure" ]; then
            FAILED_JOB="Update Existing Metadata"
          elif [ "${{ needs.automerge.result }}" == "failure" ]; then
            FAILED_JOB="Auto-merge"
          elif [ "${{ needs.post_merge_scoring.result }}" == "failure" ]; then
            FAILED_JOB="Post-Merge Scoring"
          else
            FAILED_JOB="Unknown"
          fi
          echo "failed_job=${FAILED_JOB}" >> $GITHUB_OUTPUT
          echo "Failed job: ${FAILED_JOB}"

      - name: Check for automerge-web label
        if: github.event_name == 'pull_request'
        id: check_automerge_web_notify
        env:
          GH_TOKEN: ${{ secrets.GH_MFERG_PAT }}
        run: |
          PR_NUM="${{ needs.validate_pr.outputs.pr_number }}"
          LABELS_JSON=$(gh pr view ${PR_NUM} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "is_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "is_automerge_web=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract email for notification
        if: github.event_name == 'pull_request'
        id: get_email
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
        run: |
          EMAIL=$(python brainscore_language/submission/actions_helpers.py extract_email \
            --pr-username "${{ github.event.pull_request.user.login }}" \
            --pr-title "${{ github.event.pull_request.title }}" \
            --is-automerge-web ${{ steps.check_automerge_web_notify.outputs.is_automerge_web }} || echo "")
          if [ -z "$EMAIL" ]; then
            echo "Warning: Could not extract email for user ${{ github.event.pull_request.user.login }}"
            echo "email=" >> $GITHUB_OUTPUT
            echo "email_found=false" >> $GITHUB_OUTPUT
          else
            echo "::add-mask::$EMAIL"
            echo "email=$EMAIL" >> $GITHUB_OUTPUT
            echo "email_found=true" >> $GITHUB_OUTPUT
          fi

      - name: Notify user
        if: |
          github.event_name == 'pull_request' &&
          steps.get_email.outputs.email_found == 'true'
        env:
          GMAIL_USERNAME: ${{ secrets.GMAIL_USERNAME }}
          GMAIL_PASSWORD: ${{ secrets.GMAIL_PASSWORD }}
        run: |
          python brainscore_language/submission/actions_helpers.py send_failure_email \
            "${{ steps.get_email.outputs.email }}" \
            "${{ needs.validate_pr.outputs.pr_number }}" \
            "${{ steps.failed_job.outputs.failed_job }}" \
            "$GMAIL_USERNAME" \
            "$GMAIL_PASSWORD"
      
      - name: Log email extraction failure
        if: |
          github.event_name == 'pull_request' &&
          steps.get_email.outputs.email_found == 'false'
        run: |
          echo "Could not send failure notification email - email not found for user ${{ github.event.pull_request.user.login }}"
          echo "Failure reason: ${{ steps.failed_job.outputs.failed_job }}"
          PR_NUM="${{ needs.validate_pr.outputs.pr_number }}"
          echo "PR: https://github.com/${{ github.repository }}/pull/${PR_NUM}"
