name: Plugin Submission Prepare

# Prepare workflow: Handles metadata generation/updates and commits to PR
# This workflow terminates after pushing commits, relying on synchronize events
# to trigger the validate workflow for downstream steps

on:
  pull_request:
    types: [opened, synchronize, labeled]

permissions:
  contents: write
  pull-requests: write
  checks: read
  statuses: read

env:
  DOMAIN: language
  DOMAIN_ROOT: brainscore_language
  PYTHON_VERSION: '3.11'

jobs:
  # ============================================================================
  # JOB 1: Detect and Classify Changes
  # ============================================================================
  detect_changes:
    name: "1. Detect Changes"
    runs-on: ubuntu-latest
    outputs:
      has_plugins: ${{ steps.detect.outputs.has_plugins }}
      plugin_type: ${{ steps.detect.outputs.plugin_type }}
      plugin_dirs: ${{ steps.detect.outputs.plugin_dirs }}
      has_new_models: ${{ steps.detect.outputs.has_new_models }}
      metadata_only: ${{ steps.detect.outputs.metadata_only }}
      needs_scoring: ${{ steps.detect.outputs.needs_scoring }}
      needs_mapping: ${{ steps.detect.outputs.needs_mapping }}
      needs_metadata_generation: ${{ steps.detect.outputs.needs_metadata_generation }}
      is_automergeable: ${{ steps.detect.outputs.is_automergeable }}
      plugin_info_json: ${{ steps.detect.outputs.plugin_info_json }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Get changed files
        id: changed_files
        run: |
          # Pre-merge: use GitHub API to get changed files (more reliable than git diff)
          CHANGED_FILES=$(gh pr view ${{ github.event.pull_request.number }} --json files --jq '.files[].path' | tr '\n' ' ' || echo "")
          
          # Fallback to git diff if API fails or returns empty
          if [ -z "$CHANGED_FILES" ] || [ "$CHANGED_FILES" = " " ]; then
            echo "GitHub API returned no files, trying git diff fallback..."
            BASE_REF="${{ github.event.pull_request.base.ref }}"
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
            HEAD_SHA="${{ github.event.pull_request.head.sha }}"
            
            git fetch origin ${BASE_REF} || true
            git fetch origin ${HEAD_SHA} || true
            
            if [ -n "$BASE_SHA" ] && [ -n "$HEAD_SHA" ]; then
              CHANGED_FILES=$(git diff --name-only ${BASE_SHA}...${HEAD_SHA} | tr '\n' ' ' || echo "")
            fi
            
            if [ -z "$CHANGED_FILES" ] || [ "$CHANGED_FILES" = " " ]; then
              CHANGED_FILES=$(git diff --name-only origin/${BASE_REF}...HEAD | tr '\n' ' ' || echo "")
            fi
          fi
          echo "CHANGED_FILES=${CHANGED_FILES}" >> $GITHUB_ENV
          echo "Changed files: ${CHANGED_FILES}"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Detect plugin changes
        id: detect
        run: |
          CHANGED_FILES="${{ env.CHANGED_FILES }}"
          if [ -z "$CHANGED_FILES" ]; then
            echo "No changed files detected, using empty string"
            CHANGED_FILES=""
          fi
          
          CHANGED_FILES_B64=$(echo -n "${CHANGED_FILES}" | base64 | tr -d '\n')
          PLUGIN_INFO=$(python -W ignore -c "
          from brainscore_core.plugin_management.parse_plugin_changes import get_scoring_info
          import json
          import sys
          import base64
          try:
              changed_files_b64 = '${CHANGED_FILES_B64}'
              changed_files = base64.b64decode(changed_files_b64).decode('utf-8') if changed_files_b64 else ''
              get_scoring_info(changed_files, '${{ env.DOMAIN_ROOT }}')
          except Exception as e:
              error_msg = f'Error in get_scoring_info: {type(e).__name__}: {str(e)}'
              print(error_msg, file=sys.stderr)
              print('{}')
          " 2>&1 | grep -v "^Error in get_scoring_info" | grep -v "^Warning:" | jq -c . 2>/dev/null | tail -n 1 || echo '{}')
          
          if ! echo "$PLUGIN_INFO" | jq empty 2>/dev/null; then
            echo "Warning: Invalid JSON from get_scoring_info, using empty object"
            PLUGIN_INFO='{}'
          fi
          
          echo "PLUGIN_INFO=${PLUGIN_INFO}" >> $GITHUB_ENV
          
          HAS_PLUGINS_RAW=$(echo "$PLUGIN_INFO" | jq -r 'if .modifies_plugins == true then "true" else "false" end' | head -n 1)
          HAS_PLUGINS=$(echo "$HAS_PLUGINS_RAW" | tr '[:upper:]' '[:lower:]')
          PLUGIN_TYPE=$(echo "$PLUGIN_INFO" | jq -r '.plugin_type // ""' | head -n 1)
          NEEDS_SCORING_RAW=$(echo "$PLUGIN_INFO" | jq -r '.run_score // "False"' | head -n 1)
          NEEDS_SCORING=$(echo "$NEEDS_SCORING_RAW" | tr '[:upper:]' '[:lower:]')
          IS_AUTOMERGEABLE_RAW=$(echo "$PLUGIN_INFO" | jq -r 'if .is_automergeable == true then "true" else "false" end' | head -n 1)
          IS_AUTOMERGEABLE=$(echo "$IS_AUTOMERGEABLE_RAW" | tr '[:upper:]' '[:lower:]')
          
          # Check if new_models array exists and has at least one element
          NEW_MODELS_COUNT=$(echo "$PLUGIN_INFO" | jq -r '.new_models // [] | length' | head -n 1)
          HAS_NEW_MODELS=$(if [ "$NEW_MODELS_COUNT" -gt 0 ] 2>/dev/null; then echo "true"; else echo "false"; fi)
          
          MODELS=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.models[]? // empty' | head -n 1)
          BENCHMARKS=$(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.benchmarks[]? // empty' | head -n 1)
          PLUGIN_DIRS=""
          if [ -n "$MODELS" ]; then
            for model in $(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.models[]? // empty'); do
              if [ -n "$model" ]; then
                if [ -z "$PLUGIN_DIRS" ]; then
                  PLUGIN_DIRS="${DOMAIN_ROOT}/models/${model}"
                else
                  PLUGIN_DIRS="${PLUGIN_DIRS},${DOMAIN_ROOT}/models/${model}"
                fi
              fi
            done
          fi
          if [ -n "$BENCHMARKS" ]; then
            for benchmark in $(echo "$PLUGIN_INFO" | jq -r '.changed_plugins.benchmarks[]? // empty'); do
              if [ -n "$benchmark" ]; then
                if [ -z "$PLUGIN_DIRS" ]; then
                  PLUGIN_DIRS="${DOMAIN_ROOT}/benchmarks/${benchmark}"
                else
                  PLUGIN_DIRS="${PLUGIN_DIRS},${DOMAIN_ROOT}/benchmarks/${benchmark}"
                fi
              fi
            done
          fi
          
          NON_METADATA=$(echo "$CHANGED_FILES" | tr ' ' '\n' | grep -Ev "metadata\.ya?ml" || true)
          METADATA_ONLY="false"
          if [ -z "$NON_METADATA" ] && [ "$HAS_PLUGINS" = "true" ]; then
            METADATA_ONLY="true"
          fi
          
          NEEDS_MAPPING="false"
          if [ "$DOMAIN" != "language" ] && [ "$HAS_NEW_MODELS" = "true" ] && [ "$NEEDS_SCORING" = "true" ]; then
            NEEDS_MAPPING="true"
          fi
          
          NEEDS_METADATA_GENERATION="false"
          MISSING_METADATA_DIRS=()
          if [ "$HAS_PLUGINS" = "true" ] && [ "$METADATA_ONLY" = "false" ]; then
            IFS=',' read -ra DIRS <<< "$PLUGIN_DIRS"
            for dir in "${DIRS[@]}"; do
              if [ -n "$dir" ]; then
                if [ ! -f "${dir}/metadata.yml" ] && [ ! -f "${dir}/metadata.yaml" ]; then
                  NEEDS_METADATA_GENERATION="true"
                  MISSING_METADATA_DIRS+=("${dir}")
                  echo "Plugin directory missing metadata: ${dir}"
                fi
              fi
            done
          fi
          
          echo "has_plugins=${HAS_PLUGINS:-false}" >> $GITHUB_OUTPUT
          echo "plugin_type=${PLUGIN_TYPE:-}" >> $GITHUB_OUTPUT
          echo "plugin_dirs=${PLUGIN_DIRS:-}" >> $GITHUB_OUTPUT
          echo "has_new_models=${HAS_NEW_MODELS:-false}" >> $GITHUB_OUTPUT
          echo "metadata_only=${METADATA_ONLY:-false}" >> $GITHUB_OUTPUT
          echo "needs_scoring=${NEEDS_SCORING:-false}" >> $GITHUB_OUTPUT
          echo "needs_mapping=${NEEDS_MAPPING:-false}" >> $GITHUB_OUTPUT
          echo "needs_metadata_generation=${NEEDS_METADATA_GENERATION:-false}" >> $GITHUB_OUTPUT
          echo "is_automergeable=${IS_AUTOMERGEABLE:-false}" >> $GITHUB_OUTPUT
          if [ -n "$PLUGIN_INFO" ]; then
            PLUGIN_INFO_B64=$(echo "$PLUGIN_INFO" | base64 | tr -d '\n')
            echo "plugin_info_json=${PLUGIN_INFO_B64}" >> $GITHUB_OUTPUT
          else
            echo "plugin_info_json=" >> $GITHUB_OUTPUT
          fi
          
          echo "Detection results:"
          echo "  Has plugins: ${HAS_PLUGINS}"
          echo "  Plugin type: ${PLUGIN_TYPE}"
          echo "  Plugin dirs: ${PLUGIN_DIRS}"
          echo "  Has new models: ${HAS_NEW_MODELS}"
          echo "  Metadata only: ${METADATA_ONLY}"
          echo "  Needs scoring: ${NEEDS_SCORING}"
          echo "  Needs mapping: ${NEEDS_MAPPING}"
          echo "  Needs metadata generation: ${NEEDS_METADATA_GENERATION}"
          if [ "${#MISSING_METADATA_DIRS[@]}" -gt 0 ]; then
            echo "  Plugins missing metadata: ${MISSING_METADATA_DIRS[*]}"
          fi
          echo "  Is automergeable: ${IS_AUTOMERGEABLE}"
          echo "  Changed files: ${CHANGED_FILES}"

  # ============================================================================
  # JOB 2: Validate PR (Minimal validation to proceed with mutation)
  # ============================================================================
  validate_pr:
    name: "2. Validate PR"
    needs: detect_changes
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.has_plugins == 'true'
    runs-on: ubuntu-latest
    outputs:
      all_tests_pass: ${{ steps.validate.outputs.all_tests_pass }}
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Check for automerge-web label
        id: check_label
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          LABELS_JSON=$(gh pr view ${{ github.event.pull_request.number }} --json labels)
          if echo "$LABELS_JSON" | jq -e '.labels[] | select(.name == "automerge-web")' >/dev/null; then
            echo "is_automerge_web=true" >> $GITHUB_OUTPUT
          else
            echo "is_automerge_web=false" >> $GITHUB_OUTPUT
          fi

      - name: Validate PR
        id: validate
        run: |
          RESULT=$(python brainscore_language/submission/actions_helpers.py validate_pr \
            --pr-number ${{ github.event.pull_request.number }} \
            --pr-head ${{ github.event.pull_request.head.sha }} \
            --is-automerge-web ${{ steps.check_label.outputs.is_automerge_web }})
          
          ALL_TESTS_PASS=$(echo "$RESULT" | jq -r '.all_tests_pass // false' | head -n 1)
          echo "all_tests_pass=${ALL_TESTS_PASS}" >> $GITHUB_OUTPUT

  # ============================================================================
  # JOB 3: Handle Metadata-Only PRs (Add label and terminate)
  # ============================================================================
  handle_metadata_only:
    name: "3. Handle Metadata-Only PR"
    needs: [detect_changes, validate_pr]
    if: |
      github.event_name == 'pull_request' &&
      needs.detect_changes.outputs.metadata_only == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Add labels
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh pr edit ${{ github.event.pull_request.number }} --add-label "only_update_metadata" || echo "Failed to add only_update_metadata label (may already exist on PR)"
          gh pr edit ${{ github.event.pull_request.number }} --add-label "pr_is_ready" || echo "Failed to add pr_is_ready label (may already exist on PR)"
          echo "Added 'only_update_metadata' and 'pr_is_ready' labels to PR"
          echo "Workflow terminating - validate workflow will handle metadata update via Jenkins"

  # ============================================================================
  # JOB 4: Generate Mutations and Commit (Metadata Generation + Layer Mapping)
  # All steps run in the same job so staged files persist across steps
  # ============================================================================
  generate_and_commit_mutations:
    name: "4. Generate Mutations and Commit"
    needs: [detect_changes, validate_pr]
    if: |
      github.event_name == 'pull_request' &&
      (
        (needs.detect_changes.outputs.needs_metadata_generation == 'true' && needs.validate_pr.outputs.all_tests_pass == 'true') ||
        (needs.detect_changes.outputs.needs_mapping == 'true' && needs.validate_pr.outputs.all_tests_pass == 'true')
      )
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          python -m pip install ".[test]"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: "us-east-1"

      - name: Configure Git
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

      # Step 4: Generate Metadata (stages files)
      - name: Generate metadata for plugins
        id: generate_metadata
        if: needs.detect_changes.outputs.needs_metadata_generation == 'true'
        env:
          BSC_DATABASESECRET: ${{ secrets.BSC_DATABASESECRET }}
        run: |
          IFS=',' read -ra PLUGIN_DIRS <<< "${{ needs.detect_changes.outputs.plugin_dirs }}"
          
          GENERATED_MODELS=()
          GENERATED_BENCHMARKS=()
          
          for dir in "${PLUGIN_DIRS[@]}"; do
            if [ -n "$dir" ]; then
              if [[ "$dir" == *"/models/"* ]]; then
                PLUGIN_TYPE="models"
              elif [[ "$dir" == *"/benchmarks/"* ]]; then
                PLUGIN_TYPE="benchmarks"
              else
                echo "Could not determine plugin type for ${dir}, skipping"
                continue
              fi
              
              PLUGIN_NAME=$(basename "$dir")
              
              if [ ! -f "${dir}/metadata.yml" ] && [ ! -f "${dir}/metadata.yaml" ]; then
                echo "Generating metadata for: ${dir} (type: ${PLUGIN_TYPE})"
                
                if python brainscore_language/submission/hardcoded_metadata.py "${dir}" "${PLUGIN_TYPE}"; then
                  if [ -f "${dir}/metadata.yml" ]; then
                    git add "${dir}/metadata.yml"
                    echo "Staged ${dir}/metadata.yml"
                  elif [ -f "${dir}/metadata.yaml" ]; then
                    git add "${dir}/metadata.yaml"
                    echo "Staged ${dir}/metadata.yaml"
                  fi
                  if [ "$PLUGIN_TYPE" == "models" ]; then
                    GENERATED_MODELS+=("${PLUGIN_NAME}")
                  else
                    GENERATED_BENCHMARKS+=("${PLUGIN_NAME}")
                  fi
                else
                  echo "Metadata generation failed for ${dir}, continuing..."
                fi
              else
                echo "Metadata already exists for: ${dir}, skipping generation"
              fi
            fi
          done
          
          # Store generated plugin names for commit message
          if [ ${#GENERATED_MODELS[@]} -gt 0 ]; then
            GENERATED_MODELS_STR=$(IFS=','; echo "${GENERATED_MODELS[*]}")
            echo "GENERATED_MODELS=${GENERATED_MODELS_STR}" >> $GITHUB_ENV
            echo "generated_models=${GENERATED_MODELS_STR}" >> $GITHUB_OUTPUT
          fi
          if [ ${#GENERATED_BENCHMARKS[@]} -gt 0 ]; then
            GENERATED_BENCHMARKS_STR=$(IFS=','; echo "${GENERATED_BENCHMARKS[*]}")
            echo "GENERATED_BENCHMARKS=${GENERATED_BENCHMARKS_STR}" >> $GITHUB_ENV
            echo "generated_benchmarks=${GENERATED_BENCHMARKS_STR}" >> $GITHUB_OUTPUT
          fi

      # Step 5: Layer Mapping (stages files)
      - name: Trigger layer mapping
        id: layer_mapping
        if: |
          needs.detect_changes.outputs.needs_mapping == 'true' &&
          env.DOMAIN != 'language'
        env:
          JENKINS_USER: ${{ secrets.JENKINS_MAPPING_USER }}
          JENKINS_USER_API: ${{ secrets.JENKINS_MAPPING_USER_API }}
          JENKINS_TOKEN: ${{ secrets.JENKINS_MAPPING_TOKEN }}
          JENKINS_TRIGGER: ${{ secrets.JENKINS_MAPPING_URL }}
        run: |
          PLUGIN_INFO_B64='${{ needs.detect_changes.outputs.plugin_info_json }}'
          PLUGIN_INFO=$(echo "$PLUGIN_INFO_B64" | base64 -d)
          NEW_MODELS=$(echo "$PLUGIN_INFO" | jq -r '.new_models // []')
          python brainscore_language/submission/actions_helpers.py trigger_layer_mapping \
            --new-models "$NEW_MODELS" \
            --pr-number ${{ github.event.pull_request.number }} \
            --source-repo ${{ github.event.pull_request.head.repo.clone_url }} \
            --source-branch ${{ github.event.pull_request.head.ref }}
          
          # Stage any layer mapping files that were generated
          if [ -n "$(git status --porcelain)" ]; then
            git add -A
            echo "Staged layer mapping files"
          fi

      # Step 6: Commit and Push (commits all staged files from steps 4 and 5)
      - name: Commit and push all mutations
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GH_PAT: ${{ secrets.GH_MFERG_PAT }}
        run: |
          # Commit all staged changes (metadata from step 4 + layer mapping from step 5)
          # Staged files persist across steps within the same job
          if ! git diff --cached --quiet; then
            echo "Committing all mutations (metadata generation and/or layer mapping)..."
            
            # Build commit message
            COMMIT_PARTS=()
            if [ "${{ steps.generate_metadata.outputs.generated_models }}" ] || [ "${{ steps.generate_metadata.outputs.generated_benchmarks }}" ]; then
              GENERATED_MODELS="${{ steps.generate_metadata.outputs.generated_models }}"
              GENERATED_BENCHMARKS="${{ steps.generate_metadata.outputs.generated_benchmarks }}"
              if [ -n "$GENERATED_MODELS" ] && [ -n "$GENERATED_BENCHMARKS" ]; then
                COMMIT_PARTS+=("metadata generation: models ($GENERATED_MODELS), benchmarks ($GENERATED_BENCHMARKS)")
              elif [ -n "$GENERATED_MODELS" ]; then
                COMMIT_PARTS+=("metadata generation: models ($GENERATED_MODELS)")
              elif [ -n "$GENERATED_BENCHMARKS" ]; then
                COMMIT_PARTS+=("metadata generation: benchmarks ($GENERATED_BENCHMARKS)")
              else
                COMMIT_PARTS+=("metadata generation")
              fi
            fi
            if [ "${{ steps.layer_mapping.outcome }}" == "success" ]; then
              COMMIT_PARTS+=("layer mapping")
            fi
            
            COMMIT_MSG="Auto-generate: $(IFS=', '; echo "${COMMIT_PARTS[*]}")"
            
            git commit -m "$COMMIT_MSG" || echo "Commit failed (may be no changes)"
            
            if [ -n "$GH_PAT" ]; then
              echo "Using PAT for push"
              PUSH_TOKEN="$GH_PAT"
            else
              echo "Warning: GH_PAT not set, using GITHUB_TOKEN (commits won't trigger workflows)"
              PUSH_TOKEN="$GH_TOKEN"
            fi
            # Set remote URL with token (GitHub Actions automatically masks secrets in logs)
            git remote set-url origin https://x-access-token:${PUSH_TOKEN}@github.com/${{ github.repository }}.git
            # Push and capture exit code without exposing token in error output
            if git push origin ${{ github.event.pull_request.head.ref }} >/dev/null 2>&1; then
              echo "Successfully pushed mutations to PR branch"
              
              # Add pr_is_ready label to trigger validate workflow
              echo "Adding pr_is_ready label to PR"
              gh pr edit ${{ github.event.pull_request.number }} --add-label "pr_is_ready" || echo "Failed to add label (may already exist on PR)"
              
              echo "Workflow terminating - validate workflow will run when it sees pr_is_ready label"
            else
              echo "Push failed - this may prevent workflow rerun. Check if PAT is configured correctly."
              exit 1
            fi
          else
            echo "No staged changes to commit"
          fi
