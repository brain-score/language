{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can run an existing model on an existing benchmark by calling a single function, e.g. here a `distilgpt2` on the behavioral reading-times benchmark `Futrell2018-pearsonr`. (The below output was run on a GPU, it takes ~1-2 hours on CPU to run all the text on the model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "digest text: 100%|██████████████████████████████████████████| 10256/10256 [10:41<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score ()>\n",
      "array(0.36144805)\n",
      "Attributes:\n",
      "    raw:                   <xarray.Score ()>\\narray(0.31013797)\\nAttributes:\\...\n",
      "    ceiling:               <xarray.Score ()>\\narray(0.85804302)\\nAttributes:\\...\n",
      "    model_identifier:      distilgpt2\n",
      "    benchmark_identifier:  Futrell2018-pearsonr\n"
     ]
    }
   ],
   "source": [
    "from brainscore_language import score\n",
    "\n",
    "model_score = score(model_identifier='distilgpt2', benchmark_identifier='Futrell2018-pearsonr')\n",
    "print(model_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The resulting `model_score` holds the normalized similarity between the given model on the given benchmark,\n",
    "and additionally contains more detailed information, e.g. about the correlation p-value:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score ()>\n",
      "array(0.31013797)\n",
      "Attributes:\n",
      "    rvalue:   0.3101379732378277\n",
      "    pvalue:   6.256311048629408e-217\n"
     ]
    }
   ],
   "source": [
    "print(model_score.raw)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also run e.g. an embedding model `glove-840b` on a neural benchmark `Pereira2018.243sentences-linear`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Word honey-making not present in model\n",
      "Word they're not present in model\n",
      "Word $10000 not present in model\n",
      "Word bankruptcie not present in model\n",
      "Word surge: not present in model\n",
      "Word lurche not present in model\n",
      "Word delicacie not present in model\n",
      "Word couldn't not present in model\n",
      "Word whipped-in not present in model\n",
      "Word prestigiou not present in model\n",
      "Word wellne not present in model\n",
      "Word stresse not present in model\n",
      "Word stresse not present in model\n",
      "Word blindne not present in model\n",
      "Word blindne not present in model\n",
      "Word blindne not present in model\n",
      "Word blindne not present in model\n",
      "Word infectiou not present in model\n",
      "Word deficiencie not present in model\n",
      "Word blindne not present in model\n",
      "Word isn't not present in model\n",
      "Word sweetne not present in model\n",
      "Word they're not present in model\n",
      "Word tenderne not present in model\n",
      "Word redne not present in model\n",
      "Word redne not present in model\n",
      "Word darkne not present in model\n",
      "Word half-closing not present in model\n",
      "Word food-scarce not present in model\n",
      "Word above: not present in model\n",
      "Word they're not present in model\n",
      "Word harnesse not present in model\n",
      "Word Free-climbing not present in model\n",
      "cross-validation: 100%|███████████████████████████████████████████| 10/10 [01:45<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score ()>\n",
      "array(0.23840494)\n",
      "Attributes:\n",
      "    raw:                   <xarray.Score ()>\\narray(0.08434511)\\nAttributes:\\...\n",
      "    ceiling:               <xarray.Score 'data' ()>\\narray(0.35378928)\\nAttri...\n",
      "    model_identifier:      glove-840b\n",
      "    benchmark_identifier:  Pereira2018.243sentences-linear\n"
     ]
    }
   ],
   "source": [
    "from brainscore_language import score\n",
    "\n",
    "model_score = score(model_identifier='glove-840b', benchmark_identifier='Pereira2018.243sentences-linear')\n",
    "print(model_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similarly for neural benchmarks, we can look at more detailed information, e.g. the per-split and per-voxel predictivity. Note that `model_score.raw` is the unceiled score, and `model_score.raw.raw` are then the non-aggregated scores over splits and voxels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (split: 10, neuroid: 8031)>\n",
      "array([[ 0.22522369,  0.34350706,  0.05355936, ..., -0.05345575,\n",
      "         0.09287816,  0.13193138],\n",
      "       [ 0.1944231 ,  0.42259466,  0.32561408, ..., -0.10883783,\n",
      "        -0.05270542,  0.04081422],\n",
      "       [-0.14788646,  0.02683222,  0.24090073, ...,  0.28778231,\n",
      "         0.30407656,  0.33160239],\n",
      "       ...,\n",
      "       [-0.13490506, -0.0283756 ,  0.14764324, ...,  0.08068306,\n",
      "         0.15102458,  0.18337868],\n",
      "       [ 0.2207901 ,  0.21433339,  0.56959117, ..., -0.18085951,\n",
      "        -0.02543072,  0.0530764 ],\n",
      "       [-0.09869478,  0.03248784,  0.33908366, ..., -0.19177908,\n",
      "        -0.04094738,  0.06701766]])\n",
      "Coordinates:\n",
      "  * split            (split) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * neuroid          (neuroid) MultiIndex\n",
      "  - subject          (neuroid) object '018' '018' '018' ... '426' '426' '426'\n",
      "  - voxel_num        (neuroid) int64 1001 1002 10026 10027 ... 9986 9987 9988\n",
      "  - filter_strategy  (neuroid) float64 nan nan nan nan nan ... nan nan nan nan\n",
      "  - atlas_selection  (neuroid) object 'from90to100prcnt' ... 'from90to100prcnt'\n",
      "  - roi              (neuroid) object 'LH_AntTemp' ... 'RH_PostTemp'\n",
      "  - indices_in_3d    (neuroid) int64 131599 131600 249945 ... 234883 234884\n",
      "  - col_to_coord_1   (neuroid) int64 64 65 68 69 66 67 68 ... 12 13 14 15 16 17\n",
      "  - col_to_coord_2   (neuroid) int64 51 51 29 29 51 51 30 ... 29 29 29 29 29 29\n",
      "  - col_to_coord_3   (neuroid) int64 18 18 34 34 18 18 34 ... 32 32 32 32 32 32\n",
      "  - neuroid_id       (neuroid) object '018.1001' '018.1002' ... '426.9988'\n"
     ]
    }
   ],
   "source": [
    "print(model_score.raw.raw)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
